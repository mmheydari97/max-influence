\documentclass[a4paper]{article}

\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[tmargin=1in, rmargin=1.2in, bmargin=1in, lmargin=1.2in]{geometry}
\usepackage{pdfpages}
\usepackage{listings}
\usepackage{float}
\usepackage{color}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.96,0.96,0.94}

\lstdefinestyle{mystyle}{
	backgroundcolor=\color{backcolour},   
	commentstyle=\color{codegreen},
	keywordstyle=\color{magenta},
	numberstyle=\tiny\color{codegray},
	stringstyle=\color{codepurple},
	basicstyle=\footnotesize,
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbers=left,                    
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=4
}

\lstset{style=mystyle}
\usepackage{wrapfig}

\usepackage{ptext}
\usepackage{lipsum}

\usepackage{xepersian}
\settextfont[Scale=1.1]{XB Yas}
\setlatintextfont{Arial}
\setdigitfont{Arial}


\title{ترجمه مقاله درس الگوریتم پیشرفته\\
روش تقریبی برای درخت تصمیم دودویی بهینه
}
\author{محمد مهدی حیدری\\۹۴۲۳۰۴۵}
\begin{document}
	\maketitle
	\section*{چکیده}
	\section{مقدمه}
	\paragraph{}
	در این مقاله مسئله تقریب درخت تصمبم دودویی را بررسی می‌کنیم. گری و جانسون مسئله درخت تصمیم را اینگونه تعریف می‌کنند: اگر مجموعه
	\lr{m}
	آزمون دودویی 
	\lr{$T=(T_1,... , T_m)$}
	و مجموعه 
	\lr{n}
	شی 
	\lr{$X=(X_1,..., X_n)$}
	را به ما داده باشند، خروجی یک درخت دودویی است که در آن هر برگ با یکی از اعضای مجموعه 
	\lr{X}
	و هر گره داخلی درخت با یک آزمون از مجموعه 
	\lr{T}
	علامت گذاری شده است. اگر یک شی به یک آزمون پاسخ مثبت بدهد به شاخه
	راست گره مربوط به آن آزمون حرکت می‌کند و اگر پاسخ منفی باشد به شاخه چپ می‌رود. یک مسیر از ریشه درخت تا یک برگ 
	به صورت یکتا یک شی با برچسب آن برگ را مشخص می‌کند. عمق یک برگ برابر با طول مسیر آن از ریشه درخت است.
	طول مسیر کل برای درخت برابر است با مجموع عمق تمام برگ‌های یک درخت. هدف مسئله درخت تصمیم این است که طول مسیر کل
	برای یک درخت را کمینه کند. یک شیوه معادل برای بیان مسئله این است که هر شی را یک رشته 
	\lr{m}
	ببینیم که بیت 
	\lr{i}
	ام آن نشان دهنده نتیجه‌ی آزمون 
	\lr{i}
	ام روی آن شی است که اگر جواب مثبت باشد بیت ۱ و در غیر این صورت ۰ است. در این مقاله از این شیوه از توصیف درخت
	تصمیم مثال‌هایی زده شده است که با اعضایی از مجموعه
	\lr{X}
	آنها را نشان می‌دهیم.
	اگر هیچ دو رشته‌ای در مجموعه
	\lr{X}
	یکسان نباشد، هر راه‌حل ممکن برای مسئله درخت تصمیم
	\lr{n}
	برگ خواهد داشت. در این مقاله فرض می‌کنیم همیشه ورودی یک مجموعه از رشته‌های یکتاست چون پیدا کردن رشته‌های تکراری
	به راحتی در زمان چند جمله‌ای قابل انجام است. درخت‌های تصمیم کاربردهای طبیعی بسیاری دارند از جمله: تشخیص پزشکی
	(مجموعه آزمون، علائم بیماری است.)، طراحی آزمایش (آزمون‌ها، همان آزمایش‌هایی هستند که یک ویژگی را تعیین می‌کند.)
	در واقع هیاویل و رایوست اثبات کردند که مسئله درخت تصمیم 
	\lr{NP-Complete}
	است. چون تلاش بسیاری برای ارائه الگوریتمی که درخت تصمیم بهینه را تولید می‌کند انجام شده بود.
	\paragraph{}
	در این مقاله یک الگوریتم تقریبی 
	\lr{$\ln n + 1$}
	برای مسئله درخت تصمیم ارائه می‌دهیم.
	همچنین نشان می‌دهیم که برای مسئله درخت تصمبم الگوریتم تقریبی زمان چند جمله‌ای وجود ندارد مگر اینکه 
	\lr{P=NP}
	باشد.
	با دانش فعلی ما بهترین حد بالا و پایین غیر بدیهی برای تقریب مسئله درخت تصمبم همین دو هستند.
	با توجه به قدمت زیاد و پرکاربرد بودن این مسئله، اینکه تلاش کمی برای ارائه روش تقریبی برای آن انجام شده به نظر
	اعجاب آور است.
	با این حال بررسی دقیق صورت مسئله مقداری توضیحات را ایجاب می‌کند:
	نام درخت تصمیم به یک مسئله مشابه با اندکی تفاوت نیز اشاره می‌کند که نام آنرا درخت تصمبم سازگار می‌گذاریم.
	مسئله اخیر برای تقریب بسیار سخت است. ورودی این مسئله 
	\lr{n}
	رشته دودویی است که با علامت مثبت و منفی برچسب گذاری شده است، طول هر کدام 
	\lr{m}
	است و نمونه‌های مسئله را تشکیل می‌دهد. خروجی یک درخت دودویی است که هر گره داخلی آن بیت 
	\lr{i}
	ام از نمونه‌‌ها را تست می‌کند و نمونه‌هایی که پاسخ ۱ دادند به شاخه راست و نمونه‌های با پاسخ ۰ را به شاخه چپ نگاشت
	می‌کند. هر برگ یکی از حالت‌های صحیح یا غلط را دارد. یک درخت تصمیم سازگار هر نمونه‌ی با برچسب مثبت را به یک برگ
	با برچسب صحیح و هر نمونه با برچسب منفی را به یک برگ با برچسب غلط نگاشت می‌کند. اندازه درخت در این حالت تعداد
	برگ‌ها است و مسئله درخت تصمیم سازگار به دنبال درخت تصمیمی می‌گردد که با کمترین اندازه با نمونه‌ها سازگاری داشته باشد.
	\paragraph{}
	آلکنویچ و همکارانش نشان دادند که برای هر ثابت نامنفی
	\lr{k}
	نمی‌توان از طریق درخت تصمیم با اندازه
	\lr{$s^k$}
	درخت تصمیم با اندازه
	\lr{s}
	را تخمین زد مگر اینکه
	\lr{$\epsilon < 1$}
	وجود داشته باشد که کلاس
	\lr{NP}
	زیرمجموعه 
	\lr{DTIME[$2^{m^{\epsilon}}$]}
	باشد. این موضوع نتیجه کار هانوک و همکارانش را بهبود می‌دهد که نشان می‌داد هیچ تقریب 
	\lr{$2^{\log^{\delta}s}$}
	یرای درخت تصمیم با اندازه 
	\lr{s}
	وجود ندارد که 
	\lr{$\delta < 1$}
	مگر اینکه کلاس 
	\lr{NP}
	شبه چند جمله‌ای باشد. این نتیجه برای وقتی که اندازه‌ی درخت
	\lr{$\Omega(n)$}
	باشد صادق است.
	\paragraph{}
	نتایج ما نشان می‌دهد که علیرغم ارتباط نزدیک مسئله درخت تصمیم و درخت تصمیم سازگار، این دو مسئله از نظر تقریب پذیری بسیار متفاوت هستند. درخت تصمیم سازگار برای هر ثابت
	\lr{c}
	تقریب 
	\lr{$c\ln n$}
	ندارد مگر اینکه
	\lr{P=NP}
	باشد. این در حالی است که نتایج ما از وجود داشتن چنین تقریبی با ثابت
	\lr{c > 1}
	برای مسئله درخت تصمبم خبر می‌دهد.
	همچنین ما نشان می‌دهیم که حد پایین یادگیری درخت تصمیم از نوع سازگار برای وقتی که بخواهیم به جای تعداد برگ‌ها
	مجموع طول مسیرها را کمینه کنیم نیز برقرار است. لازم به ذکر است که در مسئله درخت تصمیم، اندازه درخت معیار مفیدی
	نیست چون هر جواب ممکن برای این مسئله 
	\lr{n}
	برگ دارد. بنابراین، تفاوت در ورودی و خروجی است که باعث تفاوت در پیچیدگی تقریب این دو مسئله می‌شود و نه معیار.
	\paragraph{}
	جای تعجب ندارد که تفاوت در پیچیدگی تقریب بین مسئله درخت تصمیم و درخت تصمیم سازگار به علاوه‌ی ابهام موجود در اسم
	درخت تصمیم باعث سردرگمی در ادبیات مسئله شده است. برای مثال در ارجاع دوم مسئله درخت تصمیم با توجه به ورودی و
	خروجی همان مسئله تعریف شده ولی از نتایج منفی پژوهش هانوک و همکارانش استفاده شده است. بنابر ایم ما یکی از فعالیت‌های خود را جداسازی مسئله درخت تصمیم و درخت تصمیم سازگار از نظر پیچیدگی تقریب می‌دانیم.
	\paragraph{}
	مورت هر یک از مسائل درخت تصمیم و درخت تصمیم سازگار را نمونه‌های یکتایی از مسئله عمومی درخت تصمیم می‌داند که در آن هر یک از اعضا با یکی از 
	\lr{k}
	برچسب ممکن علامت گذاری شده است. با این فرض در مسئله درخت تصمیم این پارامتر 
	\lr{k}
	برابر با 
	\lr{n}
	است و هر عضو دقیقا یک برچسب دارد و در مسئله درخت تصمیم سازگار ۲ نوع برچسب داریم که برای هر برچسب می‌تواند چند عضو وجود داشته باشد. پس به نظر می‌آید محدودیت روی تنوع برچسب‌ها نقش اساسی در پیچیدگی تقریب در مسائل درخت تصمیم را دارد. 
	\paragraph{}
	مسئله درخت تصمیم مشترکاتی با مسئله پوشش مجموعه‌ای
	\lr{(set cover)}
	دارد. چون هر جفت از اعضا در یک درخت تصمیم معتبر دقیقا یک بار از هم جدا می‌شوند، می‌توانیم مسیر از ریشه تا یک برگ را به نوعی پوشش اعضا فرض کنیم. در این حالت هر برگ یک مسئله پوشش مجموعه‌ای را مشخص می‌کند که در آن باید 
	\lr{n-1}
	عضو باقی مانده را با استفاده از مجموعه مناسبی از بیت‌ها یا به عبارتی آزمون‌ها پوشش دهیم. در واقع آنالیز ما
	از این مشاهده الهام گرفته است. با این حال در مسئله درخت تصمیم،
	\lr{n}
	مجموعه‌ای که توسط برگ‌ها برای پوشش مجموعه‌ای معرفی می‌شوند مستقل نیستند. برای مثال بیتی که در ریشه یک درخت تصمیم
	دودویی بهینه وجود دارد، در همه‌ی
	\lr{n}
	جواب مسئله پوشش مجموعه‌ای تکرار شده است. ولی به راحتی می‌توان نمونه‌هایی از درخت تصمیم ساخت که برای آن 
	\lr{n}
	مجموعه متناظر عضو مشترکی نداشته باشند. به طور دقیق‌تر اگر پاسخ 
	\lr{n}
	مسئله پوشش مجموعه‌ای با اندازه ۱ را که از هم مستقل هستند داشته باشیم، در زمان 
	\lr{$\Theta(n^2)$}
	جواب متناظر آن در مسئله درخت تصمیم را پیدا می‌کنیم در حالی که ساخت درخت تصمیم بهینه هزینه‌ی
	\lr{$O(n\log n)$}
	دارد. در نتیجه فعل و انفعال بین مسائل پوشش مجموعه‌ای منحصر بفرد و مسئله درخت تصمیم، ظاهرا باعث تفاوت بنیادین بین این دو می‌شود.
	\paragraph{}
	مسئله پوشش مجموعه‌ای با کمترین مجموع نیز مشابه مسئله درخت تصمیم است. ورودی این مسئله مانند پوشش مجموعه‌ای است
	(مجموعه جهانی از اعضا 
	\lr{X}
	و مجموعه
	\lr{C}
	که هر عضو آن یک زسر مجموعه از 
	\lr{X}
	باشد.
	)
	، ولی خروجی یک ترتیب خطی از مجموعه‌های ۱ تا
	\lr{|C|}
	است. اگر 
	\lr{f(x)}
	اندیس اولین مجموعه از ترتیب که 
	\lr{x}
	را پوشش می‌دهد به ما بدهد، هزینه این ترتیب
	\lr{$\sum_{x\in X} f(x)$}
	خواهد بود. این هزینه با هزینه‌ی درخت تصمیم متناظر مشابه است ولی یکسان نیست چون اعضای پوشش داده شده باید همچنان
	از هم جدا شوند و در نتیجه به هزینه افزوده می‌شود. اگر به طور حریصانه مجموعه‌ای را انتخاب کنیم که بیشترین اعضای
	پوشش داده نشده را پوشش بدهد، به پاسخی تقریبی با فاکتور ۴ از مسئله پوشش مجموعه‌ای با کمترین جمع می‌رسیم. این فاکتور تقریب تنگاتنگ است مگر اینکه
	\lr{P=NP}
	برقرار باشد. مشابه مسئله پوشش مجموعه‌ای، می‌توانیم به درخت تصمیم مانند 
	\lr{n}
	نمونه از پوشش مجموعه‌ای با کمترین جمع نگاه کنیم، ولی مجددا این نمونه‌ها مستقل نیستند. پس مشکل ذاتی که برای
	مسئله پوشش مجموعه‌ای وجود داشت، در مسئله پوشش مجموعه‌ای با کمترین جمع نیز باقی می‌ماند. 
	\paragraph{}
	در قسمت بعدی الگوریتم تقریبی خود برای درخت تصمیم را توصیف و آنالیز می‌کنیم. همچنین حالتی را که به هر آزمون
	\lr{t}
	وزن داده‌شود نیز ملاحظه و می‌کنیم و نشان می‌دهیم که به فاکتور تقریب 
	\lr{$\ln n + 1$}
	نقصی وارد نمی‌شود. در قسمت سوم نشان می‌دهیم که 
	\lr{$\delta > 0$}
	پیدا می‌شود به طوری که مسئله درخت تصمیم تقریبی با فاکتور 
	\lr{$1+\delta$}
	نداشته باشد مگر اینکه
	\lr{P=NP} 
	باشد. علاوه بر این نشان می‌دهیم که کران پایین برای یادگیری درخت تصمیم سازگار برای مجموع طول مسیرهای خارجی نیز
	برقرار است. در آخر با بحث روی بعضی مسائل باز که فاصله‌ی بین کران کران بالا و پایین را شامل می‌شوند نتیجه گیری
	را انجام می‌دهیم. 
	\section{تقریب مسئله درخت تصمیم}
	\paragraph{}
	با داشتن مجموعه‌ای از رشته‌های 
	\lr{m}
	بیتی به نام
	\lr{S}
	، انتخاب یک بیت
	\lr{i}
	همواره اعضا را به دو مجموعه 
	\lr{$S^0$}
	و 
	\lr{$S^1$}
	تقسیم می‌کند که به ترتیب شامل رشته‌های با بیت
	\lr{i=0}
	و
	\lr{i=1}
	هستند. یک روش حریصانه این است که بیت
	\lr{i}
	را طوری انتخاب کنیم که اندازه این دو مجموعه کمترین اختلاف را با هم داشته باشند یا به عبارتی مجموعه
	\lr{S}
	را به متوارن‌ترین حالت ممکن بخش بندی کنند. الگوریتم حریصانه مقابل برای ساخت درخت تصمیم با مجموعه اعضای 
	\lr{n}
	عضوی به نام
	\lr{X}
	را ملاحظه کنید:
	\begin{figure}[h!]
		\centering
		\includegraphics[width=0.7\linewidth]{Pics/Greedy.png}
		\caption{الگوریتم حریصانه برای ساختن درخت تصمیم}
	\end{figure}
	\paragraph{}
	یک پیاده‌سازی سرراست این الگوریتم در زمان 
	\lr{$O(mn^2$}.
	در حالی که این الگوریتم همیشه جواب بهینه را نمی‌دهد، آنرا با فاکتور 
	\lr{$\ln n + 1$}
	تقریب می‌زند.
	\paragraph{قضیه ۱}
	اگر
	\lr{X}
	یک نمونه از درخت تصمیم با
	\lr{n}
	عضو باشد و هزینه بهینه
	\lr{$C^*$}
	باشد، آنگاه الگوریتم حریصانه درختی با هزینه‌ی حداکثر 
	\lr{$(\ln n + 1)C^*$}
	تولید می‌کند.
	\paragraph{اثبات}
	با یک نمادگذاری آغاز می‌کنیم. فرض کنید 
	\lr{T}
	درخت تصمیمی با هزینه‌ی
	\lr{C}
	باشد که الگوریتم حریصانه روی مجموعه
	\lr{X}
	ساخته است. یک جفت عضو یدون ترتیب
	\lr{\{x, y\}}
	(از این به بعد فقط یک جفت عضو) توسط گره داخلی 
	\lr{S}
	از هم جدا می‌شوند اگر 
	\lr{x}
	در یک شاخه و
	\lr{y}
	در شاخه‌ی دیگر قرار بگیرد. به خاطر داشته باشید که در یک درخت تصمیم معتبر هر جفت عضو دقیقا یک بار از هم جدا می‌شوند. بالعکس هر گره داخلی 
	\lr{S}
	مجموعه‌ای به نام 
	\lr{$\rho (S)$}
	تشکیل تعریف می‌کند که اعضای آن جفت‌هایی از اعضا هستند که توسط 
	\lr{S}
	از هم جدا شده‌اند. به این صورت:
	\[\rho(S) = \{\{x,y\}| \{x,y\} \; is \; separated \; at \; S\}\]
	برای راحتی از 
	\lr{S}
	برای نشان دادن زیردرخت‌هایی که از 
	\lr{S}
	منشعب شده‌اند نیز استفاده می‌کنیم.
	فرض کنید
	\lr{$S^+$}
	و
	\lr{$S^-$}
	دو فرزند
	\lr{S}
	باشند به طوری که 
	\lr{$|S^+| \ge |S^-|$}.
	به یاد داشته باشید که
	\lr{$|S| = |S^+| + |S^-|$}.
	تعداد مجموعه‌هایی که یک عضو به آن تعلق دارد، با طول مسیر آن از ریشه برابر است، پس هزینه
	\lr{T}
	را می‌توان با جمع اندازه‌‌های هر مجموعه
	\lr{S}
	نشان داد:
	\[C=\sum_{S\in T} |S|\]
	ما در آنالیز خود از روش بانکداری استفاده می‌کنیم تا هزینه‌ی کل درخت تصمیم حریصانه را بین تمام جفت‌های بدون ترتیبی که معرفی کردیم، پخش کنیم. چون هر مجموعه
	\lr{S}
	به اندازه اندازه خود در هزینه‌ی کل سهیم است، ما سایز آنرا به طور یکنواخت بین 
	\lr{$|S^+||S^-|$}
	جفت‌هایی از اعضا که در 
	\lr{S}
	از هم جدا شده‌اند تقسیم می‌کنیم. فرض کنید
	\lr{$c_{xy}$}
	هزینه‌ای باشد که به هر جفت عضو
	\lr{\{x, y\}}
	نسبت می‌دهیم که:
	\[c_{xy} = \frac{1}{S^{+}_{xy}}+\frac{1}{S^{-}_{xy}}\]
	در جمع سهیم هستند و هر گره
	\lr{y}
	در 
	\lr{$Z^-$}
	به اندازه:
	\[\sum_{x\in Z^+} \frac{1}{|S_{xy} \cap Z^+|}\]
	در جمع سهم دارد. برای روشن شدن موضوع، می‌توانیم 
	\lr{Z}
	را به عنوان یک گراف دو بخشی کامل ببینیم که 
	\lr{$Z^+$}
	یک بخش گره‌های آن و 
	\lr{$Z^-$}
	بخش دیگر است.
	فرض کنید 
	$b_{xy} = \frac{1}{(|S_{xy} \cap Z^-|)}$
	و
	$b_{yx} = \frac{1}{(|S_{xy} \cap Z^+|)}$
	باشد. می‌توانیم فرض کنیم که هر یال
	\newline
	\lr{(x, y)}
	که در آن
	\lr{$x \in Z^+$}
	و 
	\lr{$y \in Z^-$}
	دو هزینه دارد: یکی مربوط به 
	\lr{$x(b_{yx})$}
	و دیگری 
	\lr{$y(b_{yx})$}.
	بنابراین، هزینه‌ی کل هزینه‌ی 
	\lr{Z}
	حداکثر برابر با جمع تمام هزینه‌های
	\lr{$b_{xy}$}
	و 
	\lr{$b_{yx}$}
	است. ما می‌توانیم هزینه‌ی کل را در ابتدا با محدود کردن تمام هزینه‌های مربوط به یک گره را محدود کنیم.
	به طور خاص ما ادعا میکنیم:
	\paragraph{ادعا}
	برای هر 
	\lr{$x \in Z^+$}
	داریم:
	\[\sum_{y\in Z^-}b_{xy} = \sum_{y\in Z^-} \frac{1}{|S_{xy} \cap Z^-|} \le H(|Z^-|) \]
	\paragraph{اثبات}
	اگر 
	\lr{$Z^-$}
	\lr{m}
	عضو داشته باشد، آنگاه فرض کنید
	\lr{$(y_1,...,y_m)$}
	ترتیبی از 
	\lr{$Z^-$}
	باشد به طوری که هر چه یک عضو در درخت تصمیم حریصانه زودتر از 
	\lr{x}
	جدا شده باشد، در این ترتیب دیرتر ظاهر شده باشد (ترتیب معکوس و حالات تساوی به نحو دلخواهی شکسته شده باشد). 
	این بدین معناست که 
	\lr{$y_1$}
	آخرین و 
	\lr{$y_m$}
	اولین عضوی باشد که از 
	\lr{x}
	جدا شده است و به طور کلی
	\lr{$y_{m-t+1}$}
	\lr{t}
	امین عضوی است که از 
	\lr{x}
	جدا شده است. هنگامی که 
	\lr{$y_m$}
	از 
	\lr{x}
	جدا می‌شود، باید حداقل
	\lr{$|Z^-|$}
	عضو در 
	\lr{$S_{xym}$}
	وجود داشته باشد. با ترتیبی که ما در نظر گرفتیم اعضای باقی مانده در 
	\lr{$Z^-$}
	باید همچنان حضور داشته باشند پس:
	\lr{$Z^- \subseteq S_{xym}$}
	. بنایراین هزینه‌ای که به گره
	\lr{x}
	بخاطر یال 
	\lr{$(x, y_m)$}
	منسوب می‌شود، حداکثر
	\lr{$\frac{1}{|Z^-|}$}
	است و در حالت کلی وقتی 
	\lr{$y_t$}
	از 
	\lr{x}
	جدا می‌شود، حداقل 
	\lr{t}
	عضو از 
	\lr{$Z^-$}
	باقی می‌ماند پس هزینه
	\lr{$b_{xyt}$}
	که به یال
	\lr{$(x, y_t)$}
	نسبت داده شده حداکثر
	\lr{$\frac{1}{t}$}
	می‌شود. این بدین معناست که برای هر
	\lr{$x \in Z_+$}:
	\[\sum_{y\in Z^-} b_{xy} \le H(|Z^-|) \]
	که ادعا را ثابت می‌کند. 
	\paragraph{}
	می‌توانیم همین استدلال را برای ادعایی مشابه برای همه‌ی اعضای موجود در 
	\lr{$Z^-$}
	استفاده کنیم. با داشتن این نامساوی‌ها خواهیم داشت:
	\[\sum_{\{x,y\}\in \rho(Z)} \frac{1}{|S_{xy} \cap Z^+|} + \frac{1}{|S_{xy} \cap Z^-|} 
	\le |Z^+|H(|Z^-|) + |Z^-|H(|Z^+|)\]
	\[< |Z^+|H(|Z|) + |Z^-|H(|Z|)\]
	\[< |Z|H(|Z|)\; (since \; |Z^+|+|Z^-|=|Z|)\]
	با تعویض این نتیجه با نامساوی ابتدایی، اثبات قضیه کامل می‌شود.
	\[\sum_{Z \in T^*} \sum_{\{x,y\}\in \rho(Z)} c_{xy} \le \sum_{Z \in T^*} |Z|H(|Z|) \le \sum_{Z \in T^*} 
	|Z|H(n) = H(n)C^* \le (\ln n + 1)C^*\]
	\subsection{حالت آزمون‌های وزن دار}
	\paragraph{}
	در بسیاری از کاربردها ممکن است آزمون‌های مختلف هزینه‌های اجرای مختلفی داشته باشند. برای مثال در طراحی آزمایش
	یک آزمون تکی ممکن است تمییز دهنده‌ی خوبی برای اعضا باشد، ولی در عین حال پرهزینه باشد. اجرای چند آزمون کم‌هزینه
	می‌تواند هدف کلی را برآورده کند ولی هزینه‌ی کمتری به همراه داشته باشد. برای مدل کردن چنین سناریوهایی، ما به هر 
	بیت
	\lr{k}
	وزن
	\lr{w(k)}
	را نسبت می‌دهیم و بدون سردرگمی می‌توانیم 
	\lr{w(S)}
	را برای بیتی که در گره
	\lr{S}
	استفاده شده به کار ببریم.
	ما این مسئله را درخت تصمیم با آزمون‌های وزندار می‌نامیم. در بیان ریاضی مسئله اصلی، می‌توانیم فرض کنیم که هر آزمون وزن ۱ دارد پس هزینه معین کردن هر عضو همان طول مسیر از ریشه تا آن عضو می‌باشد. وقتی که آزمون‌ها وزن‌های غیر یکنواخت دارند، هزینه‌ی تعیین یک عضو برابر با جمع وزن‌های آزمون‌ها از ریشه تا آن عضو است که نام آن را هزینه مسیر می‌گذاریم. در نتیجه هزینه‌ی یک درخت تصمیم برابر با جمع هزینه‌ی مسیر هر عضو است. وقتی همه‌ی آزمون‌ها هزینه‌ي یکسانی دارند ما بیتی را انتخاب می‌کنیم که به مساوی‌ترین شکل ممکن اعضا را به دو گروه تفسیم می‌کند. به زبانی دیگر ما هزینه جفتی 
	\lr{$c_{xy}$}
	را کمینه می‌کنیم. با وزن‌های مساوی، هزینه‌ی یک گره داخلی همان اندازه
	\lr{S}
	است در حالی که وقتی وزن‌ها نامساوی باشند، این هزینه
	\lr{w(S) |S|}
	خواهد بود. بنابراین با فرض اینکه 
	\lr{S}
	،
	\lr{x}
	و
	\lr{y}
	را از هم جدا می‌کند، هزینه‌ي جفتی می‌شود:
	\[c_{xy} = \frac{w(S)}{|S^+|} + \frac{w(S)}{|S^-|}\]
	و الگوریتم حریصانه‌ی ما به طور بازگشتی آن بیتی را انتخاب می‌کند که این مقدار را کمینه کند. این روند منجر به
	نتیجه‌ای معادل با قضیه ۱ برای درخت تصمیم با آزمون‌های وزندار می‌شود. یک پیاده‌سازی سرراست از این الگوریتم همچنان
	در زمان
	\lr{$O(mn^2)$}
	اجرا می‌شود.  
	\paragraph{قضیه ۲}
	الگوریتم حریصانه‌ای که به طور بازگشتی بیتی را انتخاب می‌کند که معادله قبل را کمینه کند، به تقریب 
	\lr{$\ln n + 1$}
	مسئله درخت تصمیم با آزمون‌های وزن‌دار منجر می‌شود.
	\paragraph{اثبات}
	با پیروی از قواعد اثباتی که برای قضیه ۱ ارائه شد، به نتیجه‌ی مطلوب می‌رسیم. مشاهده اساسی این است که انتخاب
	بیتی که معادله را کمینه کند به این نامساوی می‌انجامد:
	\[c_{xy} \le w(Z) (\frac{1}{|S_{xy} \cap Z^+|} + \frac{1}{|S_{xy} \cap Z^-|})\]
	جون عبارت
	\lr{w(Z)}
	از جمع به بیرون فاکتور گرفته می‌شود،
	\[w(Z) \sum_{\{x,y\}\in \rho(Z)} c_{xy} \le \sum_{Z \in T^*} w(Z)|Z| H(n) \le (\ln n + 1)C^* \]
	می‌توانیم ادعای قبلی را اعمال کنیم و قضیه بدین صورت ادامه می‌یابد:
	\[\sum_{Z \in T^*} \sum_{\{x,y\}\in \rho(Z)} c_{xy} \le \sum_{Z \in T^*} w(Z)|Z|H(n) \le (\ln n + 1)C^*\]
	در اینجا 
	$C^* = \sum_{Z \in T^*} w(Z)|Z|$
	هزینه درخت بهینه است.
	\paragraph{}
	یکی دیگر از افزونه‌های طبیعی مسئله درخت تصمیم به حساب آوردن وزن برای اعضا است. در اینجا هر مسیر با عضوی که
	مسیر به آن تعلق دارد وزندهی می‌شود. متاسفانه آنالیز ما برای این حالت برقرار نیست و در بخش ۵ بیشتر درباره آن
	بحث می‌کنیم. 
	\begin{figure}[h!]
		\includegraphics[width=\linewidth]{Pics/tree.png}
		\caption{توپولوژی یک درخت بهینه}
	\end{figure}
	\section{تقریب درخت تصمیم مسئله‌ای سخت است.}
	در این بخش نشان می‌دهیم که ثابت جهانی 
	\lr{$\delta > 0$}
	وجود دارد به طوری که درخت تصمیم هیچ تقریبی با فاکتور 
	\lr{$(1+ \delta)$}
	نداشته باشد مگر اینکه، 
	\lr{P=NP}
	باشد. این مطلب بدون واسطه ایجاب می‌کند که اگر درخت تصمیم
	\lr{PTAS}
	داشته باشد، آنگاه 
	\lr{P=NP}
	خواهد بود. ما مسئله‌ای به نام
	\lr{MAX-3SAT5}
	را به مسئله درخت تصمیم با حفظ فاصله 
	\lr{(gap preserving)}
	تبدیل می‌کنیم که توسط فیج اینگونه تعریف شده است:
	
	
	ورودی: مجموعه‌ای از 
	\lr{n}
	متغیر 
	\lr{$X=\{x_1,...,x_n\}$}
	و
	\lr{m}
	عبارت منطقی
	\lr{$C = {C_1,...,C_m}$}
	که در آن هر عبارت دقیقا سه حرف دارد (حرف یک متغیر منطقی یا نفی آن است)، هیچ متغیری بیش از یک بار در یک عبارت
	ظاهر نمی‌شود و هر متغیر دقیقا در ۵ عبارت ظاهر می‌شود. به یاد داشته باشید که
	\lr{$m=\frac{5n}{3}$}
	
	خروجی: بیشینه تعداد عبارت‌هایی که با یک سری مقدار معین برای متغیرها می‌تواند خوشنود شود.
	\paragraph{}
	فیج نشان می‌دهد که برای 
	\lr{$\epsilon >0$}
	این مسئله 
	\lr{NP-Hard}
	است که بین فرمول‌های
	\lr{3SAT5}
	که قابل خوشنود شدن هستند و آنهایی که حداکثر 
	\lr{$(1-\epsilon)|C|$}
	عبارت آنها همزمان خوشنود می‌شود، تفکیک قائل شویم. از این رو ما توجه خود را به نمونه‌هایی جلب می‌کنیم که یا خوشنود پذیر هستند یا آنهایی که با هر مقداری که به متغیرها داده شود حداقل 
	\lr{$\epsilon |C|$}
	عبارت دارند که خوشنود نشده.
	\paragraph{}
	ایده این است که که 
	\lr{3SAT5}
	را به مسئله پوشش کاهش بدهیم و سپس آنرا با مسئله درخت تصمیم کاهش دهیم. نوع مسئله پوشش اهمیت دارد: با در نظر
	گرفتن طول مسیر خارجی کل، هزینه تابعی از عمق برگ‌های درخت است. پس برای کنترل هزینه باید روی عمق برگ‌ها کنترل
	پیدا کنیم. ما نشان می‌دهیم چگونه می‌توان نمونه‌های مسئله 
	\lr{3SAT5}
	را به نمونه‌های مسئله پوشش مجموعه‌ای تبدیل کنیم به طوری که هر مجموعه آن اندازه ۶ داشته باشد و هر نمونه خوشنود
	پذیر 
	\lr{3SAT5}
	دقیقا یک پوشش داشته باشد و هر نمونه خوشنودی ناپذیر برای پوشش پیدا کردن به تعدادی مجموعه با فاکتور ثابت نیاز داشته باشد. 
	\paragraph{}
	کاهش مسئله از
	\lr{3SAT5}
	به مسئله پوشش مجموعه‌ای با اندازه محدود، از اعمال تغییراتی به دست می‌آید که سیلینگ از آن استفاده کرد تا نشان
	دهد مسئله
	\lr{MinDT}
	(مسئله‌ای بسیار شبیه ولی متمایز از درخت تصمیم پایدار)، 
	\lr{PTAS}
	ندارد.
	\subsection{کاهش مسئله 
	\lr{3SAT5}
	به پوشش مجموعه‌ای}
	\paragraph{}
	با داشتن فرمول
	\lr{3SAT5}
	به نام 
	\lr{$\phi$}
	که
	\lr{n}
	متغیر و 
	\lr{m}
	عبارت دارد، ما تبدیل زمان چند جمله‌ای 
	\lr{$f(\phi)$}
	را تعریف می‌کنیم که خروجی آن یک نمونه
	\lr{(U,Z)}
	برای مسئله پوشش مجموعه‌ای است، 
	\lr{U}
	مجموعه‌ای از اعضا است و 
	\lr{Z}
	مجموعه‌ای از زیرمجموعه‌های 
	\lr{U}
	است. فرض کنید
	\lr{Y(i)}
	اندیس ۵ عبارتی باشد که در آنها
	\lr{$x_i$}
	ظاهر شده. در ابتدا مجموعه اعضا را تعریف می‌کنیم. برای هر متغیر
	\lr{$x_i$}
	۱۱ عضو درست می‌کنیم:
	\lr{$y_i$}
	،
	\lr{$a_{ij}$}
	(برای هر 
	\lr{j}
	در
	\lr{Y(i)})
	و
	\lr{$b_{ij}$}
	(مجددا برای هر 
	\lr{j}
	در
	\lr{Y(i)}).
	برای هر عبارت
	\lr{$C_j$}
	این ۳ عضو را به وجود می‌آوریم:
	\lr{$c_{j1}$}
	،
	\lr{$c_{j2}$}
	و
	\lr{$c_{j3}$}.
	در کل 
	\lr{$11n + 3m = 16n$}
	عضو وجود دارد پس
	\lr{$|U|=16n$}.
	\paragraph{}
	اکنون مجموعه‌ها را تعریف می‌کنیم. برای هر متغیر
	\lr{$x_i$}
	دو مجموعه می‌سازیم:
	\[S^{a}_{i} = \{y_i\} \cup \{a_{ij}| j \in Y(i) \} \; \; S^{b}_{i} = \{y_i\} \cup \{b_{ij}| j \in Y(i) \} \]
	اسم این مجموعه‌ها را مجموعه‌های متغیر می‌گذاریم چون از متغیرهای فرمول ساخته شده‌است. برای هر عبارت
	\lr{$C_j$}
	، ۷ مجموعه به نام مجموعه‌های عبارت می‌سازیم. هر مجموعه را به صورت مقابل می‌سازیم: فرض کنید
	\lr{$x_{u1}$}
	،
	\lr{$x_{u2}$}
	و
	\lr{$x_{u3}$}
	متغیرهایی باشند که در عبارت
	\lr{j}
	ظاهر شده‌اند. برای هر انتساب مقدار 
	\lr{z(x)}
	که باعث خوشنود شدن محلی می‌شوند (دقیقا ۷ عدد هستند)، این مجموعه را تشکیل می‌دهیم:
	\[S^{z}_{j} = \{c_{j1}, c_{j2}, c_{j3}\} \cup \{d_1, d_2, d_3\} \;\; where\;\; d_k = b_{ukj}\; if\;\; z(x_{u_k})=1 \;\; else\;\; a_{ukj} \]
	\paragraph{}
	برای مثال اگر
	\lr{$C_j = (x_1 \vee \bar{x_2} \vee x_3)$}
	آنگاه ۸ مقداردهی محلی برای متغیر‌ها وجود دارد. مقداردهی
	\lr{$x_1=1, x_2=0, x_3=0$}
	عبارت را خوشنود می‌کند پس مجموعه
	\lr{$S^{100}_{j} = \{c_{j1}, c_{j2}, c_{j3}\} \cup \{ b_{1j}, a_{2j}, a_{3j}\} $}
	شامل می‌شود. با این حال مقداردهی
	\lr{$x_1=0, x_2=1, x_3=0$}
	نمی‌تواند عبارت را خوشنود کند پس مجموعه
	\lr{$S^{010}_{j} = \{c_{j1}, c_{j2}, c_{j3}\} \cup \{ a_{1j}, b_{2j}, a_{3j}\} $}
	شامل نمی‌شود. چون برای هر عبارت ۷ مقداردهی وجود دارد که آن را به صورت محلی خوشنود کند، در کل
	\lr{7m}
	مجموعه در
	\lr{Z}
	وجود دارد. به خاطر داشته باشید که هر مجموعه دقیقا ۶ عضو دارد. کلید تبدیل مسئله این است که 
	\lr{$a_{ij}$}
	مربوط به مقداردهی مثبت به 
	\lr{$x_i$}
	و
	\lr{$b_{ij}$}
	مربوط به مقداردهی منفی به 
	\lr{$x_i$}
	است. مجموعه‌های عبارت شامل اعضایی هستند که منفی مقداردهی ما هستند، پس وقتی یک فرمول خوشنودشدنی است، همیشه می‌توان آنرا با 
	\lr{n+m}
	مجموعه پوشش داد. با این حال وقتی هیچ مقداردهی موجب خوشنود شدن وجود نداشته باشد مجموعه‌های بیشتری نیاز است.
	در نتیجه به رغم اینکه تبدیل ارائه شده با چیزی که سیلینگ ارائه داده است یکسان نیست قضیه زیر همچنان برقرار است:
	\paragraph{قضیه ۳}
	اگر
	\lr{$\phi$}
	یک فرمول خوشنود شدنی 
	\lr{3SAT5}
	باشد، آنگاه جوابی به اندازه
	\lr{m+n}
	برای
	\lr{$f(\phi)$}
	وجود دارد. اگر برای هر مقداردهی به
	\lr{$\phi$}
	حداکثر 
	\lr{$(1-\epsilon)m$}
	عبارت بتوانند همزمان خوشنود شوند آنگاه اندازه‌ی جواب 
	\lr{$f(\phi)$}
	حداقل
	\lr{$m+n+ \frac{\epsilon n}{3}$}
	خواهد بود.
	\paragraph{اثبات}
	واضح است که 
	\lr{n+m}
	مجموعه برای پوشش
	\lr{U}
	لازم است ولی وقتی 
	\lr{$\phi$}
	خوشنود شدنی است، این تعداد کافی نیز هست. اگر 
	\lr{z}
	یک مقداردهی باشد که موجب خوشنود شدن 
	\lr{$\phi$}
	شود، آنگاه برای هر متغیر
	\lr{$x_i$}
	اگر 
	\lr{$z(x_i) = 1$}
	بود 
	\lr{$S_{i}^{a}$}
	را انتخاب کنید و اگر 
	\lr{$z(x_i) = 0$}
	بود
	\lr{$S_{i}^{b}$}
	را انتخاب کنید. برای هر عبارت
	\lr{j}
	،
	\lr{$S_{j}^{z}$}
	را انتخاب کنید که مجموعه‌ای برای عبارت
	\lr{j}
	است که متناظر مقداردهی 
	\lr{z}
	است. واضح است که تمام اعضای
	\lr{$y_i$}
	و
	\lr{$c_j$}
	پوشش داده می‌شود. همچنین تمام اعضای
	\lr{$a_{ij}$}
	نیز پوشش داده می‌شود چون اگر 
	\lr{$z(x_i) = 1$}
	آنگاه
	\lr{$S_{i}^{a}$}
	و اگر 
	\lr{$z(x_i) = 0$}
	آنگاه
	\lr{$S_{j}^{z}$}
	آنرا پوشش می‌دهد. موارد
	\lr{$b_{ij}$}
	متقارن هستند پس 
	\lr{n+m}
	مجموعه کافی است. اگر 
	\lr{z}
	منجر به خوشنود شدن فرمول نشود آنگاه مجموعه‌های بیشتری نیاز خواهد بود. برای دیدن این موضوع، فرض کنید
	\lr{Y}
	جوابی برای مسئله پوشش مجموعه‌ای باشد. فرض کنید 
	\lr{Y'}
	زیر مجموعه‌ای از 
	\lr{Y}
	باشد به طوری که برای هر 
	\lr{i}
	،
	\lr{$Y'$}
	شامل اولین رخدادی از یک مجموعه باشد که
	\lr{$y_i$}
	، و برای همه‌ی
	\lr{j}
	ها اولین رخدادی از یک مجموعه باشد که
	\lr{$c_j$}
	را پوشش می‌دهد. مجموعه‌های متغیر از
	\lr{Y'}
	یک مقداردهی 
	\lr{z}
	را برای متغیرها تعریف می‌کنند. با این مقداردهی حداقل
	\lr{$\epsilon m$}
	عبارت  خوشنود نمی‌شوند. فرض کنید
	\lr{$C_j$}
	چنین عبارتی باشد، فرضا
	\lr{$(x_1, x_2, x_3)$}.
	چون این عبارت خوشنود نشده است
	\lr{$z(x_i)=0$}
	برای
	\lr{$i \in [1,3]$}.
	پس همه‌ی
	\lr{$b_i$}
	برای 
	\lr{$i \in [1,3]$}
	توسط مجموعه‌های متغیرهای پوشش داده شده‌اند. ولی مجموعه عبارت
	\lr{j}
	نمی‌تواند 
	\lr{$a_i$}
	های باقی مانده را پوشش دهد چون توسط ساختن وجود ندارد. برای پوشش دادن اعضای باقی مانده، حداقل یک مجموعه متغیر
	دیگر لازم است. این پتانسیل پوشش دادن حداکثر ۵ عضو پوشش داده نشده را دارد. پس اگر 
	\lr{$\phi$}
	خوشنودشدنی نباشد حداقل به 
	\lr{$\frac{\epsilon m}{5}= \frac{\epsilon n}{3}$}
	مجموعه بیشتر نیاز داریم. برای جزئیات بیشتر می‌توانید مرجع ۱۲ را مطالعه کنید. به خاطر داشته باشید وقتی
	\lr{$\phi$}
	خوشنود شدنی باشد پوشش مجموعه‌ای پوشش دقیق خواهد بود به این معنا که هیچ عضوی در دو مجموعه وجود ندارد.
	\paragraph{}
	اکنون ما یک تبدیل فضا نگهدار به نام
	\lr{g}
	 تعریف می‌کنیم که نمونه‌های پوشش مجموعه‌ای
	\lr{U,Z}
	 که از تبدیل 
	\lr{f}
	(تبدیل قبلی) داده شده به نمونه‌های
	\lr{X}
	درخت تصمیم تبدیل می‌کند.
	فرض کنید
	\lr{$|U| = n'$}
	و
	\lr{$|Z| = m'$}.
	برای هر عضو
	\lr{u}
	در 
	\lr{U}
	یک رشته دودویی با طول 
	\lr{4m'}
	بسازید. 
	\lr{m'}
	بیت اول با
	\lr{m'}
	مجموعه 
	\lr{Z}
	متناظر است پس نام آنرا
	بیت‌های
	\lr{Z}
	می‌گذاریم.در یک رشته برای عضو 
	\lr{u}
	بیت
	\lr{Z}
	\lr{i}
	ام برابر با ۱ خواهد بود اگر و فقط اگر 
	\lr{u}
	در مجموعه
	\lr{$Z_i$}
	موجود خواهد بود. به بیانی دیگر، 
	\lr{m'}
	بیت اول نشان‌دهنده عضویت در 
	\lr{m'}
	مجموعه‌ی
	\lr{Z}
	است.
	\lr{3m'}
	بیت آخری به ما اجازه می‌دهد اعضا را از هم تشخیص دهیم. به یاد آورید که هر مجموعه شش عضو دارد پس ما یک بیت
	\lr{Z}
	را در گره
	\lr{T}
	درخت تصمیم استفاده می‌کنیم. سپس حداکثر ۶ عضو ممکن است در شاخه ۱ 
	\lr{T}
	به دنبال هم بیایند. می‌خواهیم شکل زیردرختی را که از این اعضا تشکیل می‌شود، کنترل کنیم. یعنی می‌خواهیم تا جای
	ممکن زیردرخت کامل تشکیل دهیم. بنابراین هر مجموعه
	\lr{$Z_i$}
	در 
	\lr{Z}
	۳ بیت دیگر به هر رشته اضافه می‌کند.این بیت‌ها برای همه‌ی اعضایی که در 
	\lr{$Z_i$}
	ظاهر نشده‌اند ۰ هستند. برای آن اعضایی که در 
	\lr{$Z_i$}
	ظاهر شده باشند، بیت‌ها را جوری نسبت می‌دهیم که درخت شبه‌کامل با ارتفاع ۳ همیشه قابل تشکیل باشد. (برای مثال نیمی
	از اعضا بیت ۱ و نیمی دیگر بیت ۰ دارند و الی آخر). در کنار هم این 
	\lr{n'}
	 رشته نمونه‌های مسئله درخت تصمیم را دربر دارند. توجه کنید که تعداد اعضا عوض نمی‌شود و تبدیل چه در 
	\lr{n'}
	 و چه در 
	\lr{m'}
	چند جمله‌ای است. 
	\paragraph{ادعا}
	اگر
	\lr{$\phi$}
	یک فرمول
	\lr{3SAT5}
	خوشنود شدنی باشد، آنگاه
	\lr{$g(f(\phi))$}
	دارای درختی با هزینه‌ی حداکثر
	\lr{$\frac{64n^2}{3} + \frac{152n}{3} - 6$}
	است.
	\paragraph{اثبات}
	تمام کاری که باید انجام دهیم این است که درخت آبشارگونه‌ای که در شکل ۲ مشاهده کردید، بسازیم. بیت‌های سمت چپ
	نشان‌دهنده پوشش مجموعه‌ای بهینه است به جز ۳ بیت انتهایی (که برای تمییز دادن مجموعه باقی‌مانده نهایی استفاده شده) 
. انتخاب
	\lr{$n + m -1 = n + \frac{5n}{3} -1$}
	مجموعه به هزینه زیر منجر می‌شود:
	\[C=(-6) + \sum_{i=1}^{n+5/3n} 6i +16 = \frac{64n^2}{3}+ \frac{152n}{3} -6 \]
	\paragraph{}
	در واقع می‌توانیم نشان دهیم که
	\lr{C}
	حداقل هزینه نیز هست. برای درک این موضوع فرض کنید درخت
	\lr{T}
	متناظر با یک پوشش زیر-بهینه 
	\lr{(sub-optimal)}
	از اعضا است. این درخت حداقل عمق 
	\lr{n+m+3}
	دارد. چون هر بیت حداکثر ۶ عضو را جدا می‌کند، می‌دانیم 
	\lr{T}
	همچنین درختی آبشارگونه است ولی بعضی از زیر درخت‌‌های آن، کمتر از ۶ عضو دارند. به سادگی می‌توان نشان داد حرکت
	یک برگ که در قسمت پایین‌تری از درخت قرار دارد به بالا، هزینه‌ی کلی را کاهش می‌دهد. دلیل این اتفاق این است که
	درخت دودویی کامل جمع طول مسیرهای خارجی را کمینه می‌کند. بنابراین مفید است که تعداد زیر درخت‌های به اندازه ۶
	که در ارتفاع‌های بالاتری قرار دارند را بیشتر کنیم. چون درخت متناظر با پوشش مجموعه‌ای بهینه تماما از زیردرخت‌های
	با اندازه‌ی ۶ تشکیل شده است، کمترین هزینه را دارد. تنها چیزی که باقی مانده تا نشان دهیم این است که
	\lr{g}
	فاصله‌ی موجود در هزینه را وقتی که پوشش مجموعه‌ای حداقل
	\lr{$n+m+\frac{\epsilon n}{3}$}
	مجموعه نیاز دارد، حفظ می‌کند.
	\paragraph{ادعا}
	اگر
	\lr{$\phi$}
	یک فرمول
	\lr{3SAT5}
	باشد، به طوری که برای هر مقداردهی به آن، حداکثر
	\lr{$(1-\epsilon)|C|$}
	عبارت همزمان خوشنود شود، آنگاه هر جواب 
	\lr{$g(f(\phi))$}
	حداقل هزینه
	\lr{$C + \frac{n^2 \epsilon ^2}{18}+ \frac{n \epsilon}{6} -1$}
	دارد.
	\paragraph{اثبات}
	از قضیه ۳ می‌دانیم حداقل 
	\lr{$\frac{n \epsilon}{3}$}
	مجموعه بیشتر برای پوشش دادن تمام اعضا لازم است. با دانستن اینکه درخت باید عمق حداقل
	\lr{$n+m+\frac{n \epsilon}{3}-1$}
	برای 
	\lr{n}
	های به اندازه کافی بزرگ داشته باشد و هر بیت می‌تواند حداکثر باعث تمییز ۶ عضو شود، کمترین هزینه برای درختی
	که این قیود را رعایت کند چقدر است؟ در بهترین حالت هر یک از 
	\lr{$\frac{n \epsilon}{3}$}
	گره داخلی اضافه فقط ۱ عضو را جدا می‌کند و 
	\lr(n+m)
	گره داخلی دیگر 
	\lr{$n' - \frac{n \epsilon}{3} + 1$}
	عضو را جدا می‌کند. در بهترین حالت تا جای ممکن این زیردرخت‌ها اندازه ۶ دارند. این مسئله در قسمت سمت راست شکل
	۲ روشن شده است. راه دیگر برای فکر کردن به این درخت این است که با درخت بهینه از ادعای ۳.۱ شروع کنیم و به طور
	مکرر یک برگ از ارتفاع بالاتر حذف و به ارتفاع پایین‌تر اضافه می‌کنیم. این کار معادل با حرکت دادن یک برگ است.
	این روند راه مناسبی برای آنالیز هزینه است چون، اولین برگی که حرکت داده می‌شود حداقل ۱ واحد به هزینه اضافه می‌کند، دومین برگ حداقل ۲ واحد و همین طور تا آخر. بنابراین هزینه درخت بهینه برای حالت فاصله 
	\lr{(gap)}
	حداقل 
	\lr{$C + 1 + 2 + ... + \frac{n \epsilon}{3} - 1 = C + \frac{n^2 \epsilon^2}{18}+ \frac{n \epsilon}{6} -1$}
	خواهد بود.
	\paragraph{}
	با ترکیب ادعای ۳.۱ و ۳.۱ به نتیجه مطلوب می‌رسیم:
	\paragraph{قضیه ۴}
	تنها در حالتی
	\lr{$\delta > 0$}
	وجود دارد به طوری که مسئله درخت تصمیم الگوریتمی با فاکتور تقریب
	\lr{$(1+\delta)$}
	داشته باشد که 
	\lr{P=NP}.
	\paragraph{اثبات}
	فرض کنید برای هر
	\lr{$\delta > 0$}
	مسئله درخت تصمیم در زمان چند جمله‌ای با فاکتور
	\lr{$(1+\delta)$}
	تقریب زده شود. فرض کنید
	\lr{$0<\epsilon<1$}
	داده شده‌باشد، طوری که فاصله‌ای به اندازه
	\lr{$\epsilon$}
	در فرمول‌های خوشنودپذیر و خوشنودنشدنی
	\lr{3SAT5}
	وجود داشته باشد. 
	\lr{$\delta < \frac{\epsilon^2}{912}$}
	انتخاب کنید. حال هر نمونه خوشنودپذیر حداکثر هزینه‌ی
	\lr{$(1+\delta)C < C + \frac{n^2 \epsilon^2}{18}+ \frac{n \epsilon}{6} -1$}
	برای هر
	\lr{$n> \frac{6}{\epsilon}$}
	دارد. با ادعای ۳.۱ این یک روند زمان چندجمله‌ای برای تشخیص فرمول‌های خوشنودشدنی 
	\lr{3SAT5}
	می‌دهد که تناقض است مگر اینکه
	\lr{P=NP}.
	
	
\end{document}

