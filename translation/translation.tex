\documentclass[a4paper]{article}

\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[tmargin=1in, rmargin=1.2in, bmargin=1in, lmargin=1.2in]{geometry}
\usepackage{pdfpages}
\usepackage{listings}
\usepackage{float}
\usepackage{color}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.96,0.96,0.94}

\lstdefinestyle{mystyle}{
	backgroundcolor=\color{backcolour},   
	commentstyle=\color{codegreen},
	keywordstyle=\color{magenta},
	numberstyle=\tiny\color{codegray},
	stringstyle=\color{codepurple},
	basicstyle=\footnotesize,
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbers=left,                    
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=4
}

\lstset{style=mystyle}
\usepackage{wrapfig}

\usepackage{ptext}
\usepackage{lipsum}

\usepackage{xepersian}
\settextfont[Scale=1.1]{XB Yas}
\setlatintextfont{Arial}
\setdigitfont{Arial}


\title{ترجمه مقاله درس الگوریتم پیشرفته\\
روش تقریبی برای درخت تصمیم دودویی بهینه
}
\author{محمد مهدی حیدری\\۹۴۲۳۰۴۵}
\date{تابستان ۱۳۹۸}
\begin{document}
	\maketitle
	\section*{چکیده}
	ما یک تقریب
	\lr{$(\ln n +1)$}
	برای مسئله درخت تصمیم ارائه می‌دهیم. همچنین نشان می‌دهیم که این مسئله
	\lr{PTAS}
	ندارد مگر اینکه
	\lr{P=NP}
	باشد. یک نمونه از مسئله درخت تصمیم دارای مجموعه‌ای
	\lr{m}
	تایی از آزمون‌های دودویی
	\lr{$T=(T_1,...,T_m)$}
	و یک مجموعه
	\lr{n}
	تایی 
	\lr{$X=(X_1,..., X_n)$}
	می‌باشد. هدف گرفتن یک درخت تصمیم به عنوان خروجی است که هر گره داخلی آن یک آزمون، هر برگ آن یک عضو و مجموع طول
	مسیرهای خارجی از ریشه به برگ‌ها کمینه شود. مسئله‌ي درخت تصمیم تاریخچه‌ای غنی در علوم کامپیوتر دارد که کاربردهای
	آن از تشخیص بیماری گرفته تا طراحی آزمایش گسترده شده است. ما در حین اثبات اولین کران‌های بالا و پایین غیر بدیهی 
	برای تقریب مسئله درخت تصمیم، همچنین شرح می‌دهیم که مسئله درخت تصمیم با یک مسئله‌ی متفاوت دیگر که تشابه اسمی دارد و ما نامش را درخت تصمیم سازگار می‌گذاریم، تا چه حد از لحاظ پیچیدگی تقریب تفاوت‌های بنیادین دارد. ما در نتیجه‌گیری خود برای یک مسئله سوم به نام درخت تصمیم کمینه، یک کران پایین قوی پیدا می‌کنیم.
	\section{مقدمه}
	\paragraph{}
	در این مقاله مسئله تقریب درخت تصمبم دودویی را بررسی می‌کنیم. گری و جانسون مسئله درخت تصمیم را اینگونه تعریف می‌کنند: اگر مجموعه
	\lr{m}
	آزمون دودویی 
	\lr{$T=(T_1,... , T_m)$}
	و مجموعه 
	\lr{n}
	شی 
	\lr{$X=(X_1,..., X_n)$}
	را به ما داده باشند، خروجی یک درخت دودویی است که در آن هر برگ با یکی از اعضای مجموعه 
	\lr{X}
	و هر گره داخلی درخت با یک آزمون از مجموعه 
	\lr{T}
	علامت گذاری شده است. اگر یک شی به یک آزمون پاسخ مثبت بدهد به شاخه
	راست گره مربوط به آن آزمون حرکت می‌کند و اگر پاسخ منفی باشد به شاخه چپ می‌رود. یک مسیر از ریشه درخت تا یک برگ 
	به صورت یکتا یک شی با برچسب آن برگ را مشخص می‌کند. عمق یک برگ برابر با طول مسیر آن از ریشه درخت است.
	طول مسیر کل برای درخت برابر است با مجموع عمق تمام برگ‌های یک درخت. هدف مسئله درخت تصمیم این است که طول مسیر کل
	برای یک درخت را کمینه کند. یک شیوه معادل برای بیان مسئله این است که هر شی را یک رشته 
	\lr{m}
	ببینیم که بیت 
	\lr{i}
	ام آن نشان دهنده نتیجه‌ی آزمون 
	\lr{i}
	ام روی آن شی است که اگر جواب مثبت باشد بیت ۱ و در غیر این صورت ۰ است. در این مقاله از این شیوه از توصیف درخت
	تصمیم مثال‌هایی زده شده است که با اعضایی از مجموعه
	\lr{X}
	آنها را نشان می‌دهیم.
	اگر هیچ دو رشته‌ای در مجموعه
	\lr{X}
	یکسان نباشد، هر راه‌حل ممکن برای مسئله درخت تصمیم
	\lr{n}
	برگ خواهد داشت. در این مقاله فرض می‌کنیم همیشه ورودی یک مجموعه از رشته‌های یکتاست چون پیدا کردن رشته‌های تکراری
	به راحتی در زمان چند جمله‌ای قابل انجام است. درخت‌های تصمیم کاربردهای طبیعی بسیاری دارند از جمله: تشخیص پزشکی
	(مجموعه آزمون، علائم بیماری است.)، طراحی آزمایش (آزمون‌ها، همان آزمایش‌هایی هستند که یک ویژگی را تعیین می‌کند.)
	در واقع هیاویل و رایوست اثبات کردند که مسئله درخت تصمیم 
	\lr{NP-Complete}
	است. چون تلاش بسیاری برای ارائه الگوریتمی که درخت تصمیم بهینه را تولید می‌کند انجام شده بود.
	\paragraph{}
	در این مقاله یک الگوریتم تقریبی 
	\lr{$\ln n + 1$}
	برای مسئله درخت تصمیم ارائه می‌دهیم.
	همچنین نشان می‌دهیم که برای مسئله درخت تصمبم الگوریتم تقریبی زمان چند جمله‌ای وجود ندارد مگر اینکه 
	\lr{P=NP}
	باشد.
	با دانش فعلی ما بهترین حد بالا و پایین غیر بدیهی برای تقریب مسئله درخت تصمبم همین دو هستند.
	با توجه به قدمت زیاد و پرکاربرد بودن این مسئله، اینکه تلاش کمی برای ارائه روش تقریبی برای آن انجام شده به نظر
	اعجاب آور است.
	با این حال بررسی دقیق صورت مسئله مقداری توضیحات را ایجاب می‌کند:
	نام درخت تصمیم به یک مسئله مشابه با اندکی تفاوت نیز اشاره می‌کند که نام آنرا درخت تصمبم سازگار می‌گذاریم.
	مسئله اخیر برای تقریب بسیار سخت است. ورودی این مسئله 
	\lr{n}
	رشته دودویی است که با علامت مثبت و منفی برچسب گذاری شده است، طول هر کدام 
	\lr{m}
	است و نمونه‌های مسئله را تشکیل می‌دهد. خروجی یک درخت دودویی است که هر گره داخلی آن بیت 
	\lr{i}
	ام از نمونه‌‌ها را تست می‌کند و نمونه‌هایی که پاسخ ۱ دادند به شاخه راست و نمونه‌های با پاسخ ۰ را به شاخه چپ نگاشت
	می‌کند. هر برگ یکی از حالت‌های صحیح یا غلط را دارد. یک درخت تصمیم سازگار هر نمونه‌ی با برچسب مثبت را به یک برگ
	با برچسب صحیح و هر نمونه با برچسب منفی را به یک برگ با برچسب غلط نگاشت می‌کند. اندازه درخت در این حالت تعداد
	برگ‌ها است و مسئله درخت تصمیم سازگار به دنبال درخت تصمیمی می‌گردد که با کمترین اندازه با نمونه‌ها سازگاری داشته باشد.
	\paragraph{}
	آلکنویچ و همکارانش نشان دادند که برای هر ثابت نامنفی
	\lr{k}
	نمی‌توان از طریق درخت تصمیم با اندازه
	\lr{$s^k$}
	درخت تصمیم با اندازه
	\lr{s}
	را تخمین زد مگر اینکه
	\lr{$\epsilon < 1$}
	وجود داشته باشد که کلاس
	\lr{NP}
	زیرمجموعه 
	\lr{DTIME[$2^{m^{\epsilon}}$]}
	باشد. این موضوع نتیجه کار هانوک و همکارانش را بهبود می‌دهد که نشان می‌داد هیچ تقریب 
	\lr{$2^{\log^{\delta}s}$}
	یرای درخت تصمیم با اندازه 
	\lr{s}
	وجود ندارد که 
	\lr{$\delta < 1$}
	مگر اینکه کلاس 
	\lr{NP}
	شبه چند جمله‌ای باشد. این نتیجه برای وقتی که اندازه‌ی درخت
	\lr{$\Omega(n)$}
	باشد صادق است.
	\paragraph{}
	نتایج ما نشان می‌دهد که علیرغم ارتباط نزدیک مسئله درخت تصمیم و درخت تصمیم سازگار، این دو مسئله از نظر تقریب پذیری بسیار متفاوت هستند. درخت تصمیم سازگار برای هر ثابت
	\lr{c}
	تقریب 
	\lr{$c\ln n$}
	ندارد مگر اینکه
	\lr{P=NP}
	باشد. این در حالی است که نتایج ما از وجود داشتن چنین تقریبی با ثابت
	\lr{c > 1}
	برای مسئله درخت تصمبم خبر می‌دهد.
	همچنین ما نشان می‌دهیم که حد پایین یادگیری درخت تصمیم از نوع سازگار برای وقتی که بخواهیم به جای تعداد برگ‌ها
	مجموع طول مسیرها را کمینه کنیم نیز برقرار است. لازم به ذکر است که در مسئله درخت تصمیم، اندازه درخت معیار مفیدی
	نیست چون هر جواب ممکن برای این مسئله 
	\lr{n}
	برگ دارد. بنابراین، تفاوت در ورودی و خروجی است که باعث تفاوت در پیچیدگی تقریب این دو مسئله می‌شود و نه معیار.
	\paragraph{}
	جای تعجب ندارد که تفاوت در پیچیدگی تقریب بین مسئله درخت تصمیم و درخت تصمیم سازگار به علاوه‌ی ابهام موجود در اسم
	درخت تصمیم باعث سردرگمی در ادبیات مسئله شده است. برای مثال در ارجاع دوم مسئله درخت تصمیم با توجه به ورودی و
	خروجی همان مسئله تعریف شده ولی از نتایج منفی پژوهش هانوک و همکارانش استفاده شده است. بنابر ایم ما یکی از فعالیت‌های خود را جداسازی مسئله درخت تصمیم و درخت تصمیم سازگار از نظر پیچیدگی تقریب می‌دانیم.
	\paragraph{}
	مورت هر یک از مسائل درخت تصمیم و درخت تصمیم سازگار را نمونه‌های یکتایی از مسئله عمومی درخت تصمیم می‌داند که در آن هر یک از اعضا با یکی از 
	\lr{k}
	برچسب ممکن علامت گذاری شده است. با این فرض در مسئله درخت تصمیم این پارامتر 
	\lr{k}
	برابر با 
	\lr{n}
	است و هر عضو دقیقا یک برچسب دارد و در مسئله درخت تصمیم سازگار ۲ نوع برچسب داریم که برای هر برچسب می‌تواند چند عضو وجود داشته باشد. پس به نظر می‌آید محدودیت روی تنوع برچسب‌ها نقش اساسی در پیچیدگی تقریب در مسائل درخت تصمیم را دارد. 
	\paragraph{}
	مسئله درخت تصمیم مشترکاتی با مسئله پوشش مجموعه‌ای
	\lr{(set cover)}
	دارد. چون هر جفت از اعضا در یک درخت تصمیم معتبر دقیقا یک بار از هم جدا می‌شوند، می‌توانیم مسیر از ریشه تا یک برگ را به نوعی پوشش اعضا فرض کنیم. در این حالت هر برگ یک مسئله پوشش مجموعه‌ای را مشخص می‌کند که در آن باید 
	\lr{n-1}
	عضو باقی مانده را با استفاده از مجموعه مناسبی از بیت‌ها یا به عبارتی آزمون‌ها پوشش دهیم. در واقع آنالیز ما
	از این مشاهده الهام گرفته است. با این حال در مسئله درخت تصمیم،
	\lr{n}
	مجموعه‌ای که توسط برگ‌ها برای پوشش مجموعه‌ای معرفی می‌شوند مستقل نیستند. برای مثال بیتی که در ریشه یک درخت تصمیم
	دودویی بهینه وجود دارد، در همه‌ی
	\lr{n}
	جواب مسئله پوشش مجموعه‌ای تکرار شده است. ولی به راحتی می‌توان نمونه‌هایی از درخت تصمیم ساخت که برای آن 
	\lr{n}
	مجموعه متناظر عضو مشترکی نداشته باشند. به طور دقیق‌تر اگر پاسخ 
	\lr{n}
	مسئله پوشش مجموعه‌ای با اندازه ۱ را که از هم مستقل هستند داشته باشیم، در زمان 
	\lr{$\Theta(n^2)$}
	جواب متناظر آن در مسئله درخت تصمیم را پیدا می‌کنیم در حالی که ساخت درخت تصمیم بهینه هزینه‌ی
	\lr{$O(n\log n)$}
	دارد. در نتیجه فعل و انفعال بین مسائل پوشش مجموعه‌ای منحصر بفرد و مسئله درخت تصمیم، ظاهرا باعث تفاوت بنیادین بین این دو می‌شود.
	\paragraph{}
	مسئله پوشش مجموعه‌ای با کمترین مجموع نیز مشابه مسئله درخت تصمیم است. ورودی این مسئله مانند پوشش مجموعه‌ای است
	(مجموعه جهانی از اعضا 
	\lr{X}
	و مجموعه
	\lr{C}
	که هر عضو آن یک زسر مجموعه از 
	\lr{X}
	باشد.
	)
	، ولی خروجی یک ترتیب خطی از مجموعه‌های ۱ تا
	\lr{|C|}
	است. اگر 
	\lr{f(x)}
	اندیس اولین مجموعه از ترتیب که 
	\lr{x}
	را پوشش می‌دهد به ما بدهد، هزینه این ترتیب
	\lr{$\sum_{x\in X} f(x)$}
	خواهد بود. این هزینه با هزینه‌ی درخت تصمیم متناظر مشابه است ولی یکسان نیست چون اعضای پوشش داده شده باید همچنان
	از هم جدا شوند و در نتیجه به هزینه افزوده می‌شود. اگر به طور حریصانه مجموعه‌ای را انتخاب کنیم که بیشترین اعضای
	پوشش داده نشده را پوشش بدهد، به پاسخی تقریبی با فاکتور ۴ از مسئله پوشش مجموعه‌ای با کمترین جمع می‌رسیم. این فاکتور تقریب تنگاتنگ است مگر اینکه
	\lr{P=NP}
	برقرار باشد. مشابه مسئله پوشش مجموعه‌ای، می‌توانیم به درخت تصمیم مانند 
	\lr{n}
	نمونه از پوشش مجموعه‌ای با کمترین جمع نگاه کنیم، ولی مجددا این نمونه‌ها مستقل نیستند. پس مشکل ذاتی که برای
	مسئله پوشش مجموعه‌ای وجود داشت، در مسئله پوشش مجموعه‌ای با کمترین جمع نیز باقی می‌ماند. 
	\paragraph{}
	در قسمت بعدی الگوریتم تقریبی خود برای درخت تصمیم را توصیف و آنالیز می‌کنیم. همچنین حالتی را که به هر آزمون
	\lr{t}
	وزن داده‌شود نیز ملاحظه و می‌کنیم و نشان می‌دهیم که به فاکتور تقریب 
	\lr{$\ln n + 1$}
	نقصی وارد نمی‌شود. در قسمت سوم نشان می‌دهیم که 
	\lr{$\delta > 0$}
	پیدا می‌شود به طوری که مسئله درخت تصمیم تقریبی با فاکتور 
	\lr{$1+\delta$}
	نداشته باشد مگر اینکه
	\lr{P=NP} 
	باشد. علاوه بر این نشان می‌دهیم که کران پایین برای یادگیری درخت تصمیم سازگار برای مجموع طول مسیرهای خارجی نیز
	برقرار است. در آخر با بحث روی بعضی مسائل باز که فاصله‌ی بین کران کران بالا و پایین را شامل می‌شوند نتیجه گیری
	را انجام می‌دهیم. 
	\section{تقریب مسئله درخت تصمیم}
	\paragraph{}
	با داشتن مجموعه‌ای از رشته‌های 
	\lr{m}
	بیتی به نام
	\lr{S}
	، انتخاب یک بیت
	\lr{i}
	همواره اعضا را به دو مجموعه 
	\lr{$S^0$}
	و 
	\lr{$S^1$}
	تقسیم می‌کند که به ترتیب شامل رشته‌های با بیت
	\lr{i=0}
	و
	\lr{i=1}
	هستند. یک روش حریصانه این است که بیت
	\lr{i}
	را طوری انتخاب کنیم که اندازه این دو مجموعه کمترین اختلاف را با هم داشته باشند یا به عبارتی مجموعه
	\lr{S}
	را به متوارن‌ترین حالت ممکن بخش بندی کنند. الگوریتم حریصانه مقابل برای ساخت درخت تصمیم با مجموعه اعضای 
	\lr{n}
	عضوی به نام
	\lr{X}
	را ملاحظه کنید:
	\begin{figure}[h!]
		\centering
		\includegraphics[width=0.7\linewidth]{Pics/Greedy.png}
		\caption{الگوریتم حریصانه برای ساختن درخت تصمیم}
	\end{figure}
	\paragraph{}
	یک پیاده‌سازی سرراست این الگوریتم در زمان 
	\lr{$O(mn^2$}.
	در حالی که این الگوریتم همیشه جواب بهینه را نمی‌دهد، آنرا با فاکتور 
	\lr{$\ln n + 1$}
	تقریب می‌زند.
	\paragraph{قضیه ۱}
	اگر
	\lr{X}
	یک نمونه از درخت تصمیم با
	\lr{n}
	عضو باشد و هزینه بهینه
	\lr{$C^*$}
	باشد، آنگاه الگوریتم حریصانه درختی با هزینه‌ی حداکثر 
	\lr{$(\ln n + 1)C^*$}
	تولید می‌کند.
	\paragraph{اثبات}
	با یک نمادگذاری آغاز می‌کنیم. فرض کنید 
	\lr{T}
	درخت تصمیمی با هزینه‌ی
	\lr{C}
	باشد که الگوریتم حریصانه روی مجموعه
	\lr{X}
	ساخته است. یک جفت عضو یدون ترتیب
	\lr{\{x, y\}}
	(از این به بعد فقط یک جفت عضو) توسط گره داخلی 
	\lr{S}
	از هم جدا می‌شوند اگر 
	\lr{x}
	در یک شاخه و
	\lr{y}
	در شاخه‌ی دیگر قرار بگیرد. به خاطر داشته باشید که در یک درخت تصمیم معتبر هر جفت عضو دقیقا یک بار از هم جدا می‌شوند. بالعکس هر گره داخلی 
	\lr{S}
	مجموعه‌ای به نام 
	\lr{$\rho (S)$}
	تشکیل تعریف می‌کند که اعضای آن جفت‌هایی از اعضا هستند که توسط 
	\lr{S}
	از هم جدا شده‌اند. به این صورت:
	\[\rho(S) = \{\{x,y\}| \{x,y\} \; is \; separated \; at \; S\}\]
	برای راحتی از 
	\lr{S}
	برای نشان دادن زیردرخت‌هایی که از 
	\lr{S}
	منشعب شده‌اند نیز استفاده می‌کنیم.
	فرض کنید
	\lr{$S^+$}
	و
	\lr{$S^-$}
	دو فرزند
	\lr{S}
	باشند به طوری که 
	\lr{$|S^+| \ge |S^-|$}.
	به یاد داشته باشید که
	\lr{$|S| = |S^+| + |S^-|$}.
	تعداد مجموعه‌هایی که یک عضو به آن تعلق دارد، با طول مسیر آن از ریشه برابر است، پس هزینه
	\lr{T}
	را می‌توان با جمع اندازه‌‌های هر مجموعه
	\lr{S}
	نشان داد:
	\[C=\sum_{S\in T} |S|\]
	ما در آنالیز خود از روش بانکداری استفاده می‌کنیم تا هزینه‌ی کل درخت تصمیم حریصانه را بین تمام جفت‌های بدون ترتیبی که معرفی کردیم، پخش کنیم. چون هر مجموعه
	\lr{S}
	به اندازه اندازه خود در هزینه‌ی کل سهیم است، ما سایز آنرا به طور یکنواخت بین 
	\lr{$|S^+||S^-|$}
	جفت‌هایی از اعضا که در 
	\lr{S}
	از هم جدا شده‌اند تقسیم می‌کنیم. فرض کنید
	\lr{$c_{xy}$}
	هزینه‌ای باشد که به هر جفت عضو
	\lr{\{x, y\}}
	نسبت می‌دهیم که:
	\[c_{xy} = \frac{1}{S^{+}_{xy}}+\frac{1}{S^{-}_{xy}}\]
	در جمع سهیم هستند و هر گره
	\lr{y}
	در 
	\lr{$Z^-$}
	به اندازه:
	\[\sum_{x\in Z^+} \frac{1}{|S_{xy} \cap Z^+|}\]
	در جمع سهم دارد. برای روشن شدن موضوع، می‌توانیم 
	\lr{Z}
	را به عنوان یک گراف دو بخشی کامل ببینیم که 
	\lr{$Z^+$}
	یک بخش گره‌های آن و 
	\lr{$Z^-$}
	بخش دیگر است.
	فرض کنید 
	$b_{xy} = \frac{1}{(|S_{xy} \cap Z^-|)}$
	و
	$b_{yx} = \frac{1}{(|S_{xy} \cap Z^+|)}$
	باشد. می‌توانیم فرض کنیم که هر یال
	\newline
	\lr{(x, y)}
	که در آن
	\lr{$x \in Z^+$}
	و 
	\lr{$y \in Z^-$}
	دو هزینه دارد: یکی مربوط به 
	\lr{$x(b_{yx})$}
	و دیگری 
	\lr{$y(b_{yx})$}.
	بنابراین، هزینه‌ی کل هزینه‌ی 
	\lr{Z}
	حداکثر برابر با جمع تمام هزینه‌های
	\lr{$b_{xy}$}
	و 
	\lr{$b_{yx}$}
	است. ما می‌توانیم هزینه‌ی کل را در ابتدا با محدود کردن تمام هزینه‌های مربوط به یک گره را محدود کنیم.
	به طور خاص ما ادعا میکنیم:
	\paragraph{ادعا}
	برای هر 
	\lr{$x \in Z^+$}
	داریم:
	\[\sum_{y\in Z^-}b_{xy} = \sum_{y\in Z^-} \frac{1}{|S_{xy} \cap Z^-|} \le H(|Z^-|) \]
	\paragraph{اثبات}
	اگر 
	\lr{$Z^-$}
	\lr{m}
	عضو داشته باشد، آنگاه فرض کنید
	\lr{$(y_1,...,y_m)$}
	ترتیبی از 
	\lr{$Z^-$}
	باشد به طوری که هر چه یک عضو در درخت تصمیم حریصانه زودتر از 
	\lr{x}
	جدا شده باشد، در این ترتیب دیرتر ظاهر شده باشد (ترتیب معکوس و حالات تساوی به نحو دلخواهی شکسته شده باشد). 
	این بدین معناست که 
	\lr{$y_1$}
	آخرین و 
	\lr{$y_m$}
	اولین عضوی باشد که از 
	\lr{x}
	جدا شده است و به طور کلی
	\lr{$y_{m-t+1}$}
	\lr{t}
	امین عضوی است که از 
	\lr{x}
	جدا شده است. هنگامی که 
	\lr{$y_m$}
	از 
	\lr{x}
	جدا می‌شود، باید حداقل
	\lr{$|Z^-|$}
	عضو در 
	\lr{$S_{xym}$}
	وجود داشته باشد. با ترتیبی که ما در نظر گرفتیم اعضای باقی مانده در 
	\lr{$Z^-$}
	باید همچنان حضور داشته باشند پس:
	\lr{$Z^- \subseteq S_{xym}$}
	. بنایراین هزینه‌ای که به گره
	\lr{x}
	بخاطر یال 
	\lr{$(x, y_m)$}
	منسوب می‌شود، حداکثر
	\lr{$\frac{1}{|Z^-|}$}
	است و در حالت کلی وقتی 
	\lr{$y_t$}
	از 
	\lr{x}
	جدا می‌شود، حداقل 
	\lr{t}
	عضو از 
	\lr{$Z^-$}
	باقی می‌ماند پس هزینه
	\lr{$b_{xyt}$}
	که به یال
	\lr{$(x, y_t)$}
	نسبت داده شده حداکثر
	\lr{$\frac{1}{t}$}
	می‌شود. این بدین معناست که برای هر
	\lr{$x \in Z_+$}:
	\[\sum_{y\in Z^-} b_{xy} \le H(|Z^-|) \]
	که ادعا را ثابت می‌کند. 
	\paragraph{}
	می‌توانیم همین استدلال را برای ادعایی مشابه برای همه‌ی اعضای موجود در 
	\lr{$Z^-$}
	استفاده کنیم. با داشتن این نامساوی‌ها خواهیم داشت:
	\[\sum_{\{x,y\}\in \rho(Z)} \frac{1}{|S_{xy} \cap Z^+|} + \frac{1}{|S_{xy} \cap Z^-|} 
	\le |Z^+|H(|Z^-|) + |Z^-|H(|Z^+|)\]
	\[< |Z^+|H(|Z|) + |Z^-|H(|Z|)\]
	\[< |Z|H(|Z|)\; (since \; |Z^+|+|Z^-|=|Z|)\]
	با تعویض این نتیجه با نامساوی ابتدایی، اثبات قضیه کامل می‌شود.
	\[\sum_{Z \in T^*} \sum_{\{x,y\}\in \rho(Z)} c_{xy} \le \sum_{Z \in T^*} |Z|H(|Z|) \le \sum_{Z \in T^*} 
	|Z|H(n) = H(n)C^* \le (\ln n + 1)C^*\]
	\subsection{حالت آزمون‌های وزن دار}
	\paragraph{}
	در بسیاری از کاربردها ممکن است آزمون‌های مختلف هزینه‌های اجرای مختلفی داشته باشند. برای مثال در طراحی آزمایش
	یک آزمون تکی ممکن است تمییز دهنده‌ی خوبی برای اعضا باشد، ولی در عین حال پرهزینه باشد. اجرای چند آزمون کم‌هزینه
	می‌تواند هدف کلی را برآورده کند ولی هزینه‌ی کمتری به همراه داشته باشد. برای مدل کردن چنین سناریوهایی، ما به هر 
	بیت
	\lr{k}
	وزن
	\lr{w(k)}
	را نسبت می‌دهیم و بدون سردرگمی می‌توانیم 
	\lr{w(S)}
	را برای بیتی که در گره
	\lr{S}
	استفاده شده به کار ببریم.
	ما این مسئله را درخت تصمیم با آزمون‌های وزندار می‌نامیم. در بیان ریاضی مسئله اصلی، می‌توانیم فرض کنیم که هر آزمون وزن ۱ دارد پس هزینه معین کردن هر عضو همان طول مسیر از ریشه تا آن عضو می‌باشد. وقتی که آزمون‌ها وزن‌های غیر یکنواخت دارند، هزینه‌ی تعیین یک عضو برابر با جمع وزن‌های آزمون‌ها از ریشه تا آن عضو است که نام آن را هزینه مسیر می‌گذاریم. در نتیجه هزینه‌ی یک درخت تصمیم برابر با جمع هزینه‌ی مسیر هر عضو است. وقتی همه‌ی آزمون‌ها هزینه‌ي یکسانی دارند ما بیتی را انتخاب می‌کنیم که به مساوی‌ترین شکل ممکن اعضا را به دو گروه تفسیم می‌کند. به زبانی دیگر ما هزینه جفتی 
	\lr{$c_{xy}$}
	را کمینه می‌کنیم. با وزن‌های مساوی، هزینه‌ی یک گره داخلی همان اندازه
	\lr{S}
	است در حالی که وقتی وزن‌ها نامساوی باشند، این هزینه
	\lr{w(S) |S|}
	خواهد بود. بنابراین با فرض اینکه 
	\lr{S}
	،
	\lr{x}
	و
	\lr{y}
	را از هم جدا می‌کند، هزینه‌ي جفتی می‌شود:
	\[c_{xy} = \frac{w(S)}{|S^+|} + \frac{w(S)}{|S^-|}\]
	و الگوریتم حریصانه‌ی ما به طور بازگشتی آن بیتی را انتخاب می‌کند که این مقدار را کمینه کند. این روند منجر به
	نتیجه‌ای معادل با قضیه ۱ برای درخت تصمیم با آزمون‌های وزندار می‌شود. یک پیاده‌سازی سرراست از این الگوریتم همچنان
	در زمان
	\lr{$O(mn^2)$}
	اجرا می‌شود.  
	\paragraph{قضیه ۲}
	الگوریتم حریصانه‌ای که به طور بازگشتی بیتی را انتخاب می‌کند که معادله قبل را کمینه کند، به تقریب 
	\lr{$\ln n + 1$}
	مسئله درخت تصمیم با آزمون‌های وزن‌دار منجر می‌شود.
	\paragraph{اثبات}
	با پیروی از قواعد اثباتی که برای قضیه ۱ ارائه شد، به نتیجه‌ی مطلوب می‌رسیم. مشاهده اساسی این است که انتخاب
	بیتی که معادله را کمینه کند به این نامساوی می‌انجامد:
	\[c_{xy} \le w(Z) (\frac{1}{|S_{xy} \cap Z^+|} + \frac{1}{|S_{xy} \cap Z^-|})\]
	جون عبارت
	\lr{w(Z)}
	از جمع به بیرون فاکتور گرفته می‌شود،
	\[w(Z) \sum_{\{x,y\}\in \rho(Z)} c_{xy} \le \sum_{Z \in T^*} w(Z)|Z| H(n) \le (\ln n + 1)C^* \]
	می‌توانیم ادعای قبلی را اعمال کنیم و قضیه بدین صورت ادامه می‌یابد:
	\[\sum_{Z \in T^*} \sum_{\{x,y\}\in \rho(Z)} c_{xy} \le \sum_{Z \in T^*} w(Z)|Z|H(n) \le (\ln n + 1)C^*\]
	در اینجا 
	$C^* = \sum_{Z \in T^*} w(Z)|Z|$
	هزینه درخت بهینه است.
	\paragraph{}
	یکی دیگر از افزونه‌های طبیعی مسئله درخت تصمیم به حساب آوردن وزن برای اعضا است. در اینجا هر مسیر با عضوی که
	مسیر به آن تعلق دارد وزندهی می‌شود. متاسفانه آنالیز ما برای این حالت برقرار نیست و در بخش ۵ بیشتر درباره آن
	بحث می‌کنیم. 
	\begin{figure}[h!]
		\includegraphics[width=\linewidth]{Pics/tree.png}
		\caption{توپولوژی یک درخت بهینه}
	\end{figure}
	\section{تقریب درخت تصمیم مسئله‌ای سخت است.}
	در این بخش نشان می‌دهیم که ثابت جهانی 
	\lr{$\delta > 0$}
	وجود دارد به طوری که درخت تصمیم هیچ تقریبی با فاکتور 
	\lr{$(1+ \delta)$}
	نداشته باشد مگر اینکه، 
	\lr{P=NP}
	باشد. این مطلب بدون واسطه ایجاب می‌کند که اگر درخت تصمیم
	\lr{PTAS}
	داشته باشد، آنگاه 
	\lr{P=NP}
	خواهد بود. ما مسئله‌ای به نام
	\lr{MAX-3SAT5}
	را به مسئله درخت تصمیم با حفظ فاصله 
	\lr{(gap preserving)}
	تبدیل می‌کنیم که توسط فیج اینگونه تعریف شده است:
	
	
	ورودی: مجموعه‌ای از 
	\lr{n}
	متغیر 
	\lr{$X=\{x_1,...,x_n\}$}
	و
	\lr{m}
	عبارت منطقی
	\lr{$C = {C_1,...,C_m}$}
	که در آن هر عبارت دقیقا سه حرف دارد (حرف یک متغیر منطقی یا نفی آن است)، هیچ متغیری بیش از یک بار در یک عبارت
	ظاهر نمی‌شود و هر متغیر دقیقا در ۵ عبارت ظاهر می‌شود. به یاد داشته باشید که
	\lr{$m=\frac{5n}{3}$}
	
	خروجی: بیشینه تعداد عبارت‌هایی که با یک سری مقدار معین برای متغیرها می‌تواند خوشنود شود.
	\paragraph{}
	فیج نشان می‌دهد که برای 
	\lr{$\epsilon >0$}
	این مسئله 
	\lr{NP-Hard}
	است که بین فرمول‌های
	\lr{3SAT5}
	که قابل خوشنود شدن هستند و آنهایی که حداکثر 
	\lr{$(1-\epsilon)|C|$}
	عبارت آنها همزمان خوشنود می‌شود، تفکیک قائل شویم. از این رو ما توجه خود را به نمونه‌هایی جلب می‌کنیم که یا خوشنود پذیر هستند یا آنهایی که با هر مقداری که به متغیرها داده شود حداقل 
	\lr{$\epsilon |C|$}
	عبارت دارند که خوشنود نشده.
	\paragraph{}
	ایده این است که که 
	\lr{3SAT5}
	را به مسئله پوشش کاهش بدهیم و سپس آنرا با مسئله درخت تصمیم کاهش دهیم. نوع مسئله پوشش اهمیت دارد: با در نظر
	گرفتن طول مسیر خارجی کل، هزینه تابعی از عمق برگ‌های درخت است. پس برای کنترل هزینه باید روی عمق برگ‌ها کنترل
	پیدا کنیم. ما نشان می‌دهیم چگونه می‌توان نمونه‌های مسئله 
	\lr{3SAT5}
	را به نمونه‌های مسئله پوشش مجموعه‌ای تبدیل کنیم به طوری که هر مجموعه آن اندازه ۶ داشته باشد و هر نمونه خوشنود
	پذیر 
	\lr{3SAT5}
	دقیقا یک پوشش داشته باشد و هر نمونه خوشنودی ناپذیر برای پوشش پیدا کردن به تعدادی مجموعه با فاکتور ثابت نیاز داشته باشد. 
	\paragraph{}
	کاهش مسئله از
	\lr{3SAT5}
	به مسئله پوشش مجموعه‌ای با اندازه محدود، از اعمال تغییراتی به دست می‌آید که سیلینگ از آن استفاده کرد تا نشان
	دهد مسئله
	\lr{MinDT}
	(مسئله‌ای بسیار شبیه ولی متمایز از درخت تصمیم پایدار)، 
	\lr{PTAS}
	ندارد.
	\subsection{کاهش مسئله 
	\lr{3SAT5}
	به پوشش مجموعه‌ای}
	\paragraph{}
	با داشتن فرمول
	\lr{3SAT5}
	به نام 
	\lr{$\phi$}
	که
	\lr{n}
	متغیر و 
	\lr{m}
	عبارت دارد، ما تبدیل زمان چند جمله‌ای 
	\lr{$f(\phi)$}
	را تعریف می‌کنیم که خروجی آن یک نمونه
	\lr{(U,Z)}
	برای مسئله پوشش مجموعه‌ای است، 
	\lr{U}
	مجموعه‌ای از اعضا است و 
	\lr{Z}
	مجموعه‌ای از زیرمجموعه‌های 
	\lr{U}
	است. فرض کنید
	\lr{Y(i)}
	اندیس ۵ عبارتی باشد که در آنها
	\lr{$x_i$}
	ظاهر شده. در ابتدا مجموعه اعضا را تعریف می‌کنیم. برای هر متغیر
	\lr{$x_i$}
	۱۱ عضو درست می‌کنیم:
	\lr{$y_i$}
	،
	\lr{$a_{ij}$}
	(برای هر 
	\lr{j}
	در
	\lr{Y(i)})
	و
	\lr{$b_{ij}$}
	(مجددا برای هر 
	\lr{j}
	در
	\lr{Y(i)}).
	برای هر عبارت
	\lr{$C_j$}
	این ۳ عضو را به وجود می‌آوریم:
	\lr{$c_{j1}$}
	،
	\lr{$c_{j2}$}
	و
	\lr{$c_{j3}$}.
	در کل 
	\lr{$11n + 3m = 16n$}
	عضو وجود دارد پس
	\lr{$|U|=16n$}.
	\paragraph{}
	اکنون مجموعه‌ها را تعریف می‌کنیم. برای هر متغیر
	\lr{$x_i$}
	دو مجموعه می‌سازیم:
	\[S^{a}_{i} = \{y_i\} \cup \{a_{ij}| j \in Y(i) \} \; \; S^{b}_{i} = \{y_i\} \cup \{b_{ij}| j \in Y(i) \} \]
	اسم این مجموعه‌ها را مجموعه‌های متغیر می‌گذاریم چون از متغیرهای فرمول ساخته شده‌است. برای هر عبارت
	\lr{$C_j$}
	، ۷ مجموعه به نام مجموعه‌های عبارت می‌سازیم. هر مجموعه را به صورت مقابل می‌سازیم: فرض کنید
	\lr{$x_{u1}$}
	،
	\lr{$x_{u2}$}
	و
	\lr{$x_{u3}$}
	متغیرهایی باشند که در عبارت
	\lr{j}
	ظاهر شده‌اند. برای هر انتساب مقدار 
	\lr{z(x)}
	که باعث خوشنود شدن محلی می‌شوند (دقیقا ۷ عدد هستند)، این مجموعه را تشکیل می‌دهیم:
	\[S^{z}_{j} = \{c_{j1}, c_{j2}, c_{j3}\} \cup \{d_1, d_2, d_3\} \;\; where\;\; d_k = b_{ukj}\; if\;\; z(x_{u_k})=1 \;\; else\;\; a_{ukj} \]
	\paragraph{}
	برای مثال اگر
	\lr{$C_j = (x_1 \vee \bar{x_2} \vee x_3)$}
	آنگاه ۸ مقداردهی محلی برای متغیر‌ها وجود دارد. مقداردهی
	\lr{$x_1=1, x_2=0, x_3=0$}
	عبارت را خوشنود می‌کند پس مجموعه
	\lr{$S^{100}_{j} = \{c_{j1}, c_{j2}, c_{j3}\} \cup \{ b_{1j}, a_{2j}, a_{3j}\} $}
	شامل می‌شود. با این حال مقداردهی
	\lr{$x_1=0, x_2=1, x_3=0$}
	نمی‌تواند عبارت را خوشنود کند پس مجموعه
	\lr{$S^{010}_{j} = \{c_{j1}, c_{j2}, c_{j3}\} \cup \{ a_{1j}, b_{2j}, a_{3j}\} $}
	شامل نمی‌شود. چون برای هر عبارت ۷ مقداردهی وجود دارد که آن را به صورت محلی خوشنود کند، در کل
	\lr{7m}
	مجموعه در
	\lr{Z}
	وجود دارد. به خاطر داشته باشید که هر مجموعه دقیقا ۶ عضو دارد. کلید تبدیل مسئله این است که 
	\lr{$a_{ij}$}
	مربوط به مقداردهی مثبت به 
	\lr{$x_i$}
	و
	\lr{$b_{ij}$}
	مربوط به مقداردهی منفی به 
	\lr{$x_i$}
	است. مجموعه‌های عبارت شامل اعضایی هستند که منفی مقداردهی ما هستند، پس وقتی یک فرمول خوشنودشدنی است، همیشه می‌توان آنرا با 
	\lr{n+m}
	مجموعه پوشش داد. با این حال وقتی هیچ مقداردهی موجب خوشنود شدن وجود نداشته باشد مجموعه‌های بیشتری نیاز است.
	در نتیجه به رغم اینکه تبدیل ارائه شده با چیزی که سیلینگ ارائه داده است یکسان نیست قضیه زیر همچنان برقرار است:
	\paragraph{قضیه ۳}
	اگر
	\lr{$\phi$}
	یک فرمول خوشنود شدنی 
	\lr{3SAT5}
	باشد، آنگاه جوابی به اندازه
	\lr{m+n}
	برای
	\lr{$f(\phi)$}
	وجود دارد. اگر برای هر مقداردهی به
	\lr{$\phi$}
	حداکثر 
	\lr{$(1-\epsilon)m$}
	عبارت بتوانند همزمان خوشنود شوند آنگاه اندازه‌ی جواب 
	\lr{$f(\phi)$}
	حداقل
	\lr{$m+n+ \frac{\epsilon n}{3}$}
	خواهد بود.
	\paragraph{اثبات}
	واضح است که 
	\lr{n+m}
	مجموعه برای پوشش
	\lr{U}
	لازم است ولی وقتی 
	\lr{$\phi$}
	خوشنود شدنی است، این تعداد کافی نیز هست. اگر 
	\lr{z}
	یک مقداردهی باشد که موجب خوشنود شدن 
	\lr{$\phi$}
	شود، آنگاه برای هر متغیر
	\lr{$x_i$}
	اگر 
	\lr{$z(x_i) = 1$}
	بود 
	\lr{$S_{i}^{a}$}
	را انتخاب کنید و اگر 
	\lr{$z(x_i) = 0$}
	بود
	\lr{$S_{i}^{b}$}
	را انتخاب کنید. برای هر عبارت
	\lr{j}
	،
	\lr{$S_{j}^{z}$}
	را انتخاب کنید که مجموعه‌ای برای عبارت
	\lr{j}
	است که متناظر مقداردهی 
	\lr{z}
	است. واضح است که تمام اعضای
	\lr{$y_i$}
	و
	\lr{$c_j$}
	پوشش داده می‌شود. همچنین تمام اعضای
	\lr{$a_{ij}$}
	نیز پوشش داده می‌شود چون اگر 
	\lr{$z(x_i) = 1$}
	آنگاه
	\lr{$S_{i}^{a}$}
	و اگر 
	\lr{$z(x_i) = 0$}
	آنگاه
	\lr{$S_{j}^{z}$}
	آنرا پوشش می‌دهد. موارد
	\lr{$b_{ij}$}
	متقارن هستند پس 
	\lr{n+m}
	مجموعه کافی است. اگر 
	\lr{z}
	منجر به خوشنود شدن فرمول نشود آنگاه مجموعه‌های بیشتری نیاز خواهد بود. برای دیدن این موضوع، فرض کنید
	\lr{Y}
	جوابی برای مسئله پوشش مجموعه‌ای باشد. فرض کنید 
	\lr{Y'}
	زیر مجموعه‌ای از 
	\lr{Y}
	باشد به طوری که برای هر 
	\lr{i}
	،
	\lr{$Y'$}
	شامل اولین رخدادی از یک مجموعه باشد که
	\lr{$y_i$}
	، و برای همه‌ی
	\lr{j}
	ها اولین رخدادی از یک مجموعه باشد که
	\lr{$c_j$}
	را پوشش می‌دهد. مجموعه‌های متغیر از
	\lr{Y'}
	یک مقداردهی 
	\lr{z}
	را برای متغیرها تعریف می‌کنند. با این مقداردهی حداقل
	\lr{$\epsilon m$}
	عبارت  خوشنود نمی‌شوند. فرض کنید
	\lr{$C_j$}
	چنین عبارتی باشد، فرضا
	\lr{$(x_1, x_2, x_3)$}.
	چون این عبارت خوشنود نشده است
	\lr{$z(x_i)=0$}
	برای
	\lr{$i \in [1,3]$}.
	پس همه‌ی
	\lr{$b_i$}
	برای 
	\lr{$i \in [1,3]$}
	توسط مجموعه‌های متغیرهای پوشش داده شده‌اند. ولی مجموعه عبارت
	\lr{j}
	نمی‌تواند 
	\lr{$a_i$}
	های باقی مانده را پوشش دهد چون توسط ساختن وجود ندارد. برای پوشش دادن اعضای باقی مانده، حداقل یک مجموعه متغیر
	دیگر لازم است. این پتانسیل پوشش دادن حداکثر ۵ عضو پوشش داده نشده را دارد. پس اگر 
	\lr{$\phi$}
	خوشنودشدنی نباشد حداقل به 
	\lr{$\frac{\epsilon m}{5}= \frac{\epsilon n}{3}$}
	مجموعه بیشتر نیاز داریم. برای جزئیات بیشتر می‌توانید مرجع ۱۲ را مطالعه کنید. به خاطر داشته باشید وقتی
	\lr{$\phi$}
	خوشنود شدنی باشد پوشش مجموعه‌ای پوشش دقیق خواهد بود به این معنا که هیچ عضوی در دو مجموعه وجود ندارد.
	\paragraph{}
	اکنون ما یک تبدیل فضا نگهدار به نام
	\lr{g}
	 تعریف می‌کنیم که نمونه‌های پوشش مجموعه‌ای
	\lr{U,Z}
	 که از تبدیل 
	\lr{f}
	(تبدیل قبلی) داده شده به نمونه‌های
	\lr{X}
	درخت تصمیم تبدیل می‌کند.
	فرض کنید
	\lr{$|U| = n'$}
	و
	\lr{$|Z| = m'$}.
	برای هر عضو
	\lr{u}
	در 
	\lr{U}
	یک رشته دودویی با طول 
	\lr{4m'}
	بسازید. 
	\lr{m'}
	بیت اول با
	\lr{m'}
	مجموعه 
	\lr{Z}
	متناظر است پس نام آنرا
	بیت‌های
	\lr{Z}
	می‌گذاریم.در یک رشته برای عضو 
	\lr{u}
	بیت
	\lr{Z}
	\lr{i}
	ام برابر با ۱ خواهد بود اگر و فقط اگر 
	\lr{u}
	در مجموعه
	\lr{$Z_i$}
	موجود خواهد بود. به بیانی دیگر، 
	\lr{m'}
	بیت اول نشان‌دهنده عضویت در 
	\lr{m'}
	مجموعه‌ی
	\lr{Z}
	است.
	\lr{3m'}
	بیت آخری به ما اجازه می‌دهد اعضا را از هم تشخیص دهیم. به یاد آورید که هر مجموعه شش عضو دارد پس ما یک بیت
	\lr{Z}
	را در گره
	\lr{T}
	درخت تصمیم استفاده می‌کنیم. سپس حداکثر ۶ عضو ممکن است در شاخه ۱ 
	\lr{T}
	به دنبال هم بیایند. می‌خواهیم شکل زیردرختی را که از این اعضا تشکیل می‌شود، کنترل کنیم. یعنی می‌خواهیم تا جای
	ممکن زیردرخت کامل تشکیل دهیم. بنابراین هر مجموعه
	\lr{$Z_i$}
	در 
	\lr{Z}
	۳ بیت دیگر به هر رشته اضافه می‌کند.این بیت‌ها برای همه‌ی اعضایی که در 
	\lr{$Z_i$}
	ظاهر نشده‌اند ۰ هستند. برای آن اعضایی که در 
	\lr{$Z_i$}
	ظاهر شده باشند، بیت‌ها را جوری نسبت می‌دهیم که درخت شبه‌کامل با ارتفاع ۳ همیشه قابل تشکیل باشد. (برای مثال نیمی
	از اعضا بیت ۱ و نیمی دیگر بیت ۰ دارند و الی آخر). در کنار هم این 
	\lr{n'}
	 رشته نمونه‌های مسئله درخت تصمیم را دربر دارند. توجه کنید که تعداد اعضا عوض نمی‌شود و تبدیل چه در 
	\lr{n'}
	 و چه در 
	\lr{m'}
	چند جمله‌ای است. 
	\paragraph{ادعا}
	اگر
	\lr{$\phi$}
	یک فرمول
	\lr{3SAT5}
	خوشنود شدنی باشد، آنگاه
	\lr{$g(f(\phi))$}
	دارای درختی با هزینه‌ی حداکثر
	\lr{$\frac{64n^2}{3} + \frac{152n}{3} - 6$}
	است.
	\paragraph{اثبات}
	تمام کاری که باید انجام دهیم این است که درخت آبشارگونه‌ای که در شکل ۲ مشاهده کردید، بسازیم. بیت‌های سمت چپ
	نشان‌دهنده پوشش مجموعه‌ای بهینه است به جز ۳ بیت انتهایی (که برای تمییز دادن مجموعه باقی‌مانده نهایی استفاده شده) 
. انتخاب
	\lr{$n + m -1 = n + \frac{5n}{3} -1$}
	مجموعه به هزینه زیر منجر می‌شود:
	\[C=(-6) + \sum_{i=1}^{n+5/3n} 6i +16 = \frac{64n^2}{3}+ \frac{152n}{3} -6 \]
	\paragraph{}
	در واقع می‌توانیم نشان دهیم که
	\lr{C}
	حداقل هزینه نیز هست. برای درک این موضوع فرض کنید درخت
	\lr{T}
	متناظر با یک پوشش زیر-بهینه 
	\lr{(sub-optimal)}
	از اعضا است. این درخت حداقل عمق 
	\lr{n+m+3}
	دارد. چون هر بیت حداکثر ۶ عضو را جدا می‌کند، می‌دانیم 
	\lr{T}
	همچنین درختی آبشارگونه است ولی بعضی از زیر درخت‌‌های آن، کمتر از ۶ عضو دارند. به سادگی می‌توان نشان داد حرکت
	یک برگ که در قسمت پایین‌تری از درخت قرار دارد به بالا، هزینه‌ی کلی را کاهش می‌دهد. دلیل این اتفاق این است که
	درخت دودویی کامل جمع طول مسیرهای خارجی را کمینه می‌کند. بنابراین مفید است که تعداد زیر درخت‌های به اندازه ۶
	که در ارتفاع‌های بالاتری قرار دارند را بیشتر کنیم. چون درخت متناظر با پوشش مجموعه‌ای بهینه تماما از زیردرخت‌های
	با اندازه‌ی ۶ تشکیل شده است، کمترین هزینه را دارد. تنها چیزی که باقی مانده تا نشان دهیم این است که
	\lr{g}
	فاصله‌ی موجود در هزینه را وقتی که پوشش مجموعه‌ای حداقل
	\lr{$n+m+\frac{\epsilon n}{3}$}
	مجموعه نیاز دارد، حفظ می‌کند.
	\paragraph{ادعا}
	اگر
	\lr{$\phi$}
	یک فرمول
	\lr{3SAT5}
	باشد، به طوری که برای هر مقداردهی به آن، حداکثر
	\lr{$(1-\epsilon)|C|$}
	عبارت همزمان خوشنود شود، آنگاه هر جواب 
	\lr{$g(f(\phi))$}
	حداقل هزینه
	\lr{$C + \frac{n^2 \epsilon ^2}{18}+ \frac{n \epsilon}{6} -1$}
	دارد.
	\paragraph{اثبات}
	از قضیه ۳ می‌دانیم حداقل 
	\lr{$\frac{n \epsilon}{3}$}
	مجموعه بیشتر برای پوشش دادن تمام اعضا لازم است. با دانستن اینکه درخت باید عمق حداقل
	\lr{$n+m+\frac{n \epsilon}{3}-1$}
	برای 
	\lr{n}
	های به اندازه کافی بزرگ داشته باشد و هر بیت می‌تواند حداکثر باعث تمییز ۶ عضو شود، کمترین هزینه برای درختی
	که این قیود را رعایت کند چقدر است؟ در بهترین حالت هر یک از 
	\lr{$\frac{n \epsilon}{3}$}
	گره داخلی اضافه فقط ۱ عضو را جدا می‌کند و 
	\lr(n+m)
	گره داخلی دیگر 
	\lr{$n' - \frac{n \epsilon}{3} + 1$}
	عضو را جدا می‌کند. در بهترین حالت تا جای ممکن این زیردرخت‌ها اندازه ۶ دارند. این مسئله در قسمت سمت راست شکل
	۲ روشن شده است. راه دیگر برای فکر کردن به این درخت این است که با درخت بهینه از ادعای ۳.۱ شروع کنیم و به طور
	مکرر یک برگ از ارتفاع بالاتر حذف و به ارتفاع پایین‌تر اضافه می‌کنیم. این کار معادل با حرکت دادن یک برگ است.
	این روند راه مناسبی برای آنالیز هزینه است چون، اولین برگی که حرکت داده می‌شود حداقل ۱ واحد به هزینه اضافه می‌کند، دومین برگ حداقل ۲ واحد و همین طور تا آخر. بنابراین هزینه درخت بهینه برای حالت فاصله 
	\lr{(gap)}
	حداقل 
	\lr{$C + 1 + 2 + ... + \frac{n \epsilon}{3} - 1 = C + \frac{n^2 \epsilon^2}{18}+ \frac{n \epsilon}{6} -1$}
	خواهد بود.
	\paragraph{}
	با ترکیب ادعای ۳.۱ و ۳.۱ به نتیجه مطلوب می‌رسیم:
	\paragraph{قضیه ۴}
	تنها در حالتی
	\lr{$\delta > 0$}
	وجود دارد به طوری که مسئله درخت تصمیم الگوریتمی با فاکتور تقریب
	\lr{$(1+\delta)$}
	داشته باشد که 
	\lr{P=NP}.
	\paragraph{اثبات}
	فرض کنید برای هر
	\lr{$\delta > 0$}
	مسئله درخت تصمیم در زمان چند جمله‌ای با فاکتور
	\lr{$(1+\delta)$}
	تقریب زده شود. فرض کنید
	\lr{$0<\epsilon<1$}
	داده شده‌باشد، طوری که فاصله‌ای به اندازه
	\lr{$\epsilon$}
	در فرمول‌های خوشنودپذیر و خوشنودنشدنی
	\lr{3SAT5}
	وجود داشته باشد. 
	\lr{$\delta < \frac{\epsilon^2}{912}$}
	انتخاب کنید. حال هر نمونه خوشنودپذیر حداکثر هزینه‌ی
	\lr{$(1+\delta)C < C + \frac{n^2 \epsilon^2}{18}+ \frac{n \epsilon}{6} -1$}
	برای هر
	\lr{$n> \frac{6}{\epsilon}$}
	دارد. با ادعای ۳.۱ این یک روند زمان چندجمله‌ای برای تشخیص فرمول‌های خوشنودشدنی 
	\lr{3SAT5}
	می‌دهد که تناقض است مگر اینکه
	\lr{P=NP}.
	\subsection{سختی تقریب درخت سازگار تحت طول مسیر خارجی کلی}
	آلکنوویچ و همکارانش نشان دادند که ممکن نیست بتوان درخت تصمیم با اندازه
	\lr{k}
	را با درخت تصمیم با اندازه
	\lr{$s^k$}
	برای هر ثابت
	\lr{$k \ge 0$}
	تقریب زد مگر اینکه برای یک
	\lr{$\epsilon < 1$}
	کلاس 
	\lr{NP}
	داخل کلاس
	\lr{$DTIME[2^{m^\epsilon}]$}
	قرار بگیرد. در اینجا درخت تصمیم به نوع سازگار آن اشاره می‌کند و معیار اندازه درخت است. در این بخش نشان می‌دهیم
	این نتایج سختی برای کمینه کردن طول کلی مسیر خارجی در درخت تصمیم سازگار نیز برقرار است.
	قضیه ما روی مشاهده‌ای تکیه می‌کند که اگر 
	\lr{I}
	یک نمونه از درخت تصمیم پایدار باشد و طول کل مسیر خارجی آن
	\lr{s}
	باشد، آنگاه اندازه‌ی درخت 
	\lr{I}
	حداقل 
	\lr{$\Omega(\sqrt{s})$}
	است. در غیر این صورت، درخت با اندازه کمتر طول کلی مسیر خارجی کمتری دارد که تناقض است. حالتی که کمترین طول
	کلی مسیر خارجی 
	\lr{s}
	با کمترین اندازه
	\lr{$\Omega(\sqrt{s})$}
	متناظر است مربوط به درخت آبشار گونه است. یعنی درختی که در هر عمق یک برگ دارد و در آخرین قسمت دو برگ دارد.
	\paragraph{قضیه ۵}
	اگر یک تقریب
	\lr{$s^k$}
	به ازای یک ثابت
	\lr{k>0}
	برای درخت تصمیم با طول مسیر خارجی کل 
	\lr{s}
	وجود داشته باشد، آنگاه برای یک 
	\lr{$\epsilon < 1$}
	کلاس 
	\lr{NP}
	داخل کلاس
	\lr{$DTIME[2^{m^\epsilon}]$}
	قرار دارد. 
	\paragraph{اثبات}
	فرض کنید
	\lr{I}
	یک نمونه از درخت تصمیم سازگار با کمترین طول مسیر خارجی کلی 
	\lr{$s=r^2$}
	باشد. در نتیجه حداقل اندازه درخت
	\lr{$\Omega(r)$}
	خواهد بود. حال اگر یک تقریب
	\lr{$s^k$}
	برای یک مقداری از 
	\lr{k}
	وجود داشته باشد، آنگاه یک تقریب 
	\lr{$\Omega(r^{2k})= r^{k'}$}
	به ازای یک ثابت
	\lr{k'}
	برای درخت تصمیم سازگار تحت کمترین اندازه درخت موجود است که این یک تناقض است.
	\section{حدود پایین جدید برای تقریب درخت تصمیم کمینه}
	\paragraph{}
	یک مسئله مشابه درخت تصمیم سازگار، پیدا کردن درخت‌های تصمیم کوچک و معادل است. این مسئله 
	\lr{MinDT}
	یا درخت تصمیم کمینه، به عنوان ورودی درخت تصمیم
	\lr{T}
	روی 
	\lr{n}
	متغیر را می‌گیرد که از نوع سازگار است(یعنی یک تابع از 
	\lr{$\{0,1\}^n$}
	به 
	\lr{$\{0,1\}$})
	و به دنبال کوچکترین درخت تصمیم
	\lr{T'}
	می‌گردد (کوچکترین مجددا از نظر تعداد برگ) که از نظر عملکرد معادل
	\lr{T}
	باشد. در اینجا عملکرد معادل به این معناست که 
	\lr{T}
	و
	\lr{T'}
	یک تابع را روی رشته‌های دودویی به طول 
	\lr{n}
	محاسبه می‌کنند. زانتما و بودلاندر ابتدا این مسئله را تعریف و اثبات کردند که
	\lr{NP-hard}
	است. سیلینگ نشان داد این مسئله الگوریتم تقریبی با فاکتور ثابت ندارد مگر اینکه
	\lr{P=NP}
	باشد. این نتایج منفی از یک ویژگی درخت تصمیم سرچشمه می‌گیرد که خودش را بهبود می‌دهد و اگر نتایج مرجع ۷ را مربع
	کنیم همچنان برقرار می‌ماند. این ویژگی که خودش را بهبود می‌دهد در اینجا بررسی می‌شود، چگونگی تعمیم آن نشان داده
	می‌شود و سپس آرگومان‌ها و تکنیک‌های مرجع ۷ اعمال می‌شود تا نشان دهیم هیچ الگوریتم تقریبی
	\lr{$2^{\log^{\delta}s}$}
	ای وجود ندارد (در اینجا 
	\lr{s}
	اندازه درخت بهینه و
	\lr{$\delta < 1$}
	است)، مگر اینکه 
	\lr{$NP \subseteq DTIME[2^{ploylog\;n}]$}
	\paragraph{لم ۲}
	فرض کنید
	\lr{f}
	و
	\lr{g}
	توابع دودویی به ترتیب روی متغیر‌های دودویی مستقل
	\lr{n}
	و
	\lr{m}
	باشند. اگر 
	\lr{$MIN(f\oplus g)$}
	اندازه کوچکترین درخت تصمیمی باشد که
	\lr{$f\oplus g$}
	را محاسبه می‌کند، آنگاه
	\lr{$MIN(f\oplus g) = MIN(f).MIN(g)$}
	خواهد بود. به طور مشابه، اگر 
	\lr{T}
	درختی با اندازه‌ی
	\lr{|T|}
	باشد که 
	\lr{$f\oplus g$}
	را محاسبه می‌کند، آنگاه درخت‌های
	\lr{$T_f$}
	و
	\lr{$T_g$}
	که به ترتیب 
	\lr{f}
	و
	\lr{g}
	را محاسبه می‌کنند، در زمان چندجمله‌ای قابل ساخت هستند به طوری که 
	\lr{$|T_f|.|T_g| \le |T|$}
	باشد.
	\paragraph{}
	اثبات لم۲ 
	\lr{T}
	را به ناحیه‌های
	\lr{f}
	و ناحیه‌های 
	\lr{g}
	بر اساس بزرگترین بخش‌های پیوسته درخت تقسیم می‌کند که بیت‌های را به طور انحصاری از 
	\lr{f}
	یا
	\lr{g}
	بررسی می‌کنند. ایده این است که نواحی نزدیک برگ‌ها ممکن است با والد‌های خود عوض شوند و که نواحی پیوسته بزرگتری
	را شکل دهند تا اینکه 
	\lr{$T_f$}
	و 
	\lr{$T_g$}
	به راحتی قابل تشخیص باشند. تعمیم این نتیجه به جزئیات بیشتری نیاز دارد:
	\paragraph{لم۳}
	فرض کنید
	\lr{F}
	مجموعه‌ای از توابع دودویی باشد به طوری که
	\lr{$f_i: \{0,1\}^{n_i} \rightarrow \{0,1\}$}.
	فرض کنید
	\lr{$g=\bigoplus_{i=1}^{r}f_i$}.
	اگر 
	\lr{MIN(g)}
	اندازه‌ی کوچکترین درخت تصمیم باشد که 
	\lr{g}
	را محاسبه می‌کند، آنگاه
	\lr{$MIN(g)=\prod_{i=1}^{r}MIN(f_i)$}.
	به طور مشابه اگر 
	\lr{T}
	یک درخت با اندازه
	\lr{|T|}
	باشد که
	\lr{g}
	را در زمان چند جمله‌ای محاسبه می‌کند، می‌توانیم برای هر
	\lr{$f_i$}
	درخت
	\lr{$T_i$}
	را بسازیم به طوری که
	\lr{$\prod_{i=1}^{r}|T_i| \le |T|$}.
	\paragraph{اثبات}
	اثبات این لم مانند تعمیمی از تکنیک مربع‌سازی است که در مرجع ۷ استفاده شده. درخت را کاسته بنامید هرگاه هیچ 
	مسیری شامل دو رخداد از یک متغیر نباشد. در این اثبات ما فرض می‌کنیم تمام درخت‌ها کاسته هستند چون انجام این کار
	به سرعت امکان‌پذیر است. به سادگی می‌توان نشان داد: 
	\lr{$MIN(g)\le \prod_{i=1}^{r}MIN(f_i)$}. 
	تنها کافی است درخت را با استفاده از الحاق توابع در 
	\lr{F}
	بسازید. این کار منجر به یک درخت برای 
	\lr{g}
	می‌شود که اندازه آن دقیقا
	\lr{$\prod_{i=1}^{r}MIN(n_i)$}
	می‌شود. طرف دیگر پیچیده‌تر است. فرض کنید
	\lr{$x_i$}
	متغیری از تابع
	\lr{$f_i$}
	را نشان می‌دهد. درخت در فرم استاندارد است اگر روی هر مسیر از ریشه به برگ،بعد از متغیر
	\lr{$x_i$}
	فقط متغیرهای
	\lr{$x_{i'}$}
	آمده باشد که
	\lr{$i' \ge i$}.
	اگر ریشه درخت (یا زیردرخت)
	\lr{$x_i$}
	باشد آنگاه فرض کنید
	\lr{$s(x_i)=(s_1...s_t)$}
	ریشه‌های زیردرخت‌های 
	\lr{$x_i$}
	را نشان دهد که اولین گره‌های در طول مسیر از ریشه هستند که متغیرهایی دارند که از
	\lr{i}
	متفاوت است.
	\paragraph{}
	یک درخت که ریشه آن
	\lr{$x_i$}
	است زیردرخت معادل نام دارد اگر هر درختی که ریشه آن یکی از
	\lr{$s(x_i)$}
	ها باشد از نظر ساختاری دقیقا یکسان باشد مگر در برگ‌ها. هنگامی که یک درخت در فرم استاندارد قرار دارد و زیردرخت
	معادل باشد، به راحتی می‌توان توابعی که هر 
	\lr{$f_i$}
	را محاسبه می‌کنند بازیابی کرد. برای همین هر درختی که 
	\lr{g}
	را محاسبه می‌کند، در فرم استاندارد است و زیردرخت معادل است اندازه‌ای بزرگتر یا مساوی ضرب اندازه‌های توابع
	مرکب خود دارد. ما معمولا درخت را با ریشه‌ی آن نشان می‌دهیم. پس گفتن اینکه
	\lr{$x_i$}
	در فرم استاندارد است واقعا به این معناست که درختی با آن ریشه در فرم استاندارد است. اثبات با استفاده از استقرا
	روی ارتفاع زیر درخت‌های
	\lr{T}
	است که در فرم استاندارد بوده و زیر درخت معادل هستند. به طور بدیهی صحیح است که هر برگ در فرم استاندارد است و
	زیر درخت معادل است. حالا فرض کنید یک گره داخلی 
	\lr{$x_i$}
	را با فرزند چپ
	\lr{$x_{i'}$}
	و فرزند راست
	\lr{$x_{i"}$}
	فرض کنید که هردو در فرم استاندارد و زیردرخت معادل باشند. بدون از دست رفتن عمومیت مسئله، فرض کنید
	\lr{$i' \le i"$}.
	ما باید دو حالت را مد نظر قرار دهیم: اگر 
	\lr{$i \le i'$}
	آنگاه 
	\lr{$x_i$}
	در فرم استاندارد است. بعلاوه ما ادعای مقابل را انجام می‌دهیم:
	\paragraph{ادعا}
	هر دو درخت از 
	\lr{$s(x_i)$}
	از لحاظ عملکرد بخاطر ویژگی قطبیت معادل هستند.
	\paragraph{اثبات}
	فرض کنید دوتا از درخت‌های
	\lr{$s(x_i)$}
	توابع متفاوتی را محاسبه کنند. پس دو رشته‌ی
	\lr{$w_1$}
	و
	\lr{$w_2$}
	وجود خواهد داشت که فقط در متغیرهای 
	\lr{$f_i$}
	با هم تفاوت دارند (به طور دقیق آن متغیرهایی در 
	\lr{$x_i$}
	و فراتر)، خروجی‌های متفاوتی روی
	\lr{$g\oplus f_i$}
	(تابع 
	\lr{g}
	که 
	\lr{$f_i$}
	از آن حذف شده است.) دارند که این یک تناقض است چون 
	\lr{$g\oplus f_i$}
	متغیرهای
	\lr{$f_i$}
	را نادیده می‌گیرد پس
	\lr{$g\oplus f_i(w_1) = g\oplus f_i(w_2)$}.
	\paragraph{}
	اکنون می‌توانیم از
	\lr{$s(x_i)$}
	کوچکترینش را برداشته و آنرا در طول
	\lr{$s(x_i)$}
	های باقی مانده تکرار کنیم و در مواقع لزوم علامت آن را برای برگ‌ها تغییر دهیم. این درخت با ریشه
	\lr{$x_i$}
	اکنون زیر درخت معادل است و استقرا برقرار است. از طرف دیگر، اگر
	\lr{$i>i'$}
	باشد آنگاه
	\lr{$x_i$}
	در فرم استاندارد نخواهد بود. با استفاده از استدلال مشابه ادعای ۴ می‌توانیم نشان دهیم که 
	\lr{$x_{i'}$}
	و
	\lr{$x_{i"}$}
	از نظر عملکرد تا جایی که به تفاوت‌های
	\lr{$f_i$}
	 می‌رسیم، معادل هستند. اگر
	\lr{$f_i$}
	نسبت به
	\lr{$x_i$}
	ثابت نباشد، آنگاه بین 
	\lr{$x_{i'}$}
 	و
 	\lr{$x_{i"}$}
 	درختی را بیابید که کمترین گره‌های ممکن را تا رسیدن به نواحی
 	\lr{$f_i$}
 	خود داشته باشد. بدون از دست رفتن عمومیت، بگویید این
 	\lr{$x_{i'}$}
 	است. بالای هر زیر درخت 
 	\lr{$f_i$}
 	در درخت
 	\lr{$xـ{i'}$}،
 	\lr{$xـi$}
 	را وارد کنید و کاری کنید
 	\lr{$f_i$}
 	فرزند چپ
 	\lr{$xـi$}
 	باشد. حالا ریشه‌ی هر ناحیه
 	\lr{$f_i$}
 	را از 
 	\lr{$x_{i"}$}
 	انتخاب کنید (آنها به جز برچسب‌ها یکسان هستند.) و آن و زیر درخت‌هایش را فرزند راست هر
 	\lr{$x_i$}
 	قرار دهید و مجددا در صورت نیاز برچسب‌ها را منفی کنید. واضح است که به ازای
 	\lr{$x_i=0$}
 	درختی با ریشه
 	\lr{$x_{i'}$}
 	مقداری مشابه با درخت قبلی را محاسبه می‌کند. برای اینکه ببینید چرا برای  
 	\lr{$x_i=1$}
 	نیز این نتیجه درست است، به خاطر آورید که 
 	\lr{$x_{i'}$}
 	و
 	\lr{$x_{i"}$}
 	از نظر عملکرد معادل هستند تا جایی که به
 	\lr{$f_i$}
 	برسیم. پس هر ناحیه
 	\lr{$f_j$}
 	،
 	\lr{$(j \ne i)$}
 	باید به طور مستقل بتواند برچسب خودش را محاسبه کند. پس تمام
 	\lr{$f_j$}
 	ها تمییزدهنده‌ی کافی هستند. با ساختن
 	\lr{$x_{i'}$}
 	همچنان در فرم استاندارد و زیر درخت معادل است. ما
 	\lr{$x_{i"}$}
 	را پاک می‌کنیم، 
 	\lr{$x_{i'}$}
 	را به ریشه ارتقا می‌دهیم و با خاصیتی از آن که کوچکترین زیردرخت‌ها به هر
 	\lr{$f_i$}
 	را دارد، می‌دانیم که این درخت جدید از درخت اصلی
 	\lr{$x_i$}
 	کوچکتر است.
 	\paragraph{}
 	با در دست داشتن لم۳ این امکان وجود دارد که قضیه زیر را اثبات کنیم:
 	\paragraph{قضیه ۶}
 	یرای هر 
 	\lr{$\delta < 1$}
 	هیچ تقریب 
 	\lr{$2^{\log^\delta s}$}
 	ای برای درخت تصمیم کمینه وجود ندارد که در آن
 	\lr{s}
 	اندازه درخت بهینه است، مگر اینکه کلاس
 	\lr{NP}
 	شبه چندجمله‌ای باشد.
 	\paragraph{}
 	اثبات این قضیه اساسا یکسان با اثباتی است که برای درخت تصمیم سازگار ارائه شد. ما در اینجا برای کامل بودن آن 
 	را می‌نویسیم.
 	\paragraph{اثبات}
 	فرض کنید چنین تقریبی وحود دارد. درخت داده شده‌ی 
 	\lr{T}
 	را بگیرید و آن را به توان 
 	\lr{d}
 	برسانید که
 	\lr{$d=\log^r(n)$}
 	است و
 	\lr{$r=\frac{2\delta}{1-\delta}$}
 	می‌باشد. این کار زمان
 	\lr{$n^d=n^{\log^r(n)} = 2^{polylog(n)}$}
 	می‌گیرد. کوچک‌ترین جواب برای
 	\lr{$T^d$}
 	اندازه‌ی
 	\lr{$s^d$}
 	دارد. بنابراین تقریب اخیر جوابی به ما می‌دهد که حداکثر اندازه‌اش
 	\lr{$s^d2^{\log^\delta(s^d)}$}
 	دارد که از آن می‌توانیم برای 
 	\lr{T}
 	درختی پیدا کنیم که اندازه‌ی آن:
 	\[s2^{d^{\delta -1}\log^\delta(s)} = s2^{\log^{\frac{2\delta(\delta-1)}{1-\delta}}(n)\log^\delta(s)} =
 	s2^{log^{-2\delta}(n)\log^\delta(s)} = s2^{log^{-2\delta}(n)\log^\delta(s^d)}\]
 	که پیچیدگی زمانی آن
 	\lr{O(s)}
 	است. این با نتیجه‌ی سیلینگ که هیچ تقریب با فاکتور ثابتی وجود ندارد در تناقض است.
 	\paragraph{}
 	لم ۳ معادل با این است که مکررا مسئله را مربع سازی کنیم و تقریب را بهبود بخشیم. در اینجا نشان می‌دهیم که 
 	هیچ تقریب
 	\lr{$\log n$}
 	ای برای درخت تصمیم کمینه وجود ندارد مگر اینکه
 	\lr{NP}
 	در زمان 
 	\lr{$O(n^{\log \log(n)})$}
 	قرار بگیرد. با افزایش تعداد شمارش‌ها می‌توانیم قضیه ۶ را نیز اثبات کنیم.
 	\paragraph{قضیه ۷}
 	اگر نمونه‌ای از درخت تصمیم کمینه وجود داشته باشد که کوچکترین جواب آن با اندازه
 	\lr{s}
 	یک تقریب
 	\lr{$\log(s)$}
 	داشته باشد، آنگاه
 	\lr{NP}
 	،
 	\lr{$n^{O(\log \log (n))}$}
 	است.
 	\paragraph{اثبات}
 	فرض کنید یک تقریب
 	\lr{$\log(s)$}
 	وجود داشته‌باشد. آنگاه بعد از
 	\lr{k}
 	امین شمارش مربع سازی، ما یک تقریب
 	\lr{$(\log(s))^{\frac{1}{2^k}}$}
 	خواهیم داشت. در نتیجه بعد از 
 	\lr{$k=\log(\log(\log(s)))$}
 	شمارش به تقریبی با فاکتور ثابت می‌رسیم. چون هر پیمایش به طور موثر اندازه مسئله را ۲ برابر می‌کند، زمان کلی برای
 	\lr{k}
 	شمارش خواهد بود:
 	\[n^{2^k} = n^{2^{\log \log \log (s)}} = n^{\log \log(s)}= n^{O(\log \log(s))}\]
 	چون
 	\lr{$s \le n$}
 	است قضیه برقرار است. 
 	\section{مسائل باز و بحث}
 	در این مقاله ما برای مسئله درخت تصمیم یک تقریب
 	\lr{$(\ln n + 1)$}
 	ارائه کردیم. در کنار آن با داشتن اولین حد بالای غیر بدیهی، نتایج مقصود دومی را هم برآورده می‌کند. این نتایج
 	تقریب مسئله درخت تصمیم را از یک مسئله بسیار مشابه که برای تقریب زدن بسیار دشوار بود و نام آن را درخت تصمیم
 	سازگار گذاشتیم، جدا می‌کند. بعلاوه ما یک تبدیل زمان چند جمله‌ای از 
 	\lr{MAX-3SAT5}
 	به مسئله درخت تصمیم ارائه دادیم که فاصله‌ی 
 	\lr{$\epsilon$}
 	بین فرمول‌های خوشنود شدنی و خوشنودی‌ناپذیر را حفظ می‌کرد. این بدین معناست که مسئله درخت تصمیم
 	\lr{PTAS}
 	ندارد مگر اینکه
 	\lr{P=NP}
 	باشد.
 	\paragraph{}
 	برجسته‌ترین مسئله باز فاصله‌ی بین حد بالا و پایین در تقریب مسئله درخت تصمیم است. بزرگ‌کردن فاصله با استفاده از
 	تکنیک‌های مرجع ۷ برای درخت تصمیم سازگار، برای مسئله درخت تصمیم کار نمی‌کند. در آنجا یک نمونه از
 	درخت تصمیم سازگار مربع می‌شد و تقریب
 	\lr{$\alpha$}
 	روی آن اعمال می‌شد و جواب به نمونه اصلی بازگردانده می‌شد که تقریب
 	\lr{$\sqrt{\alpha}$}
 	بود. تکرار این روند به کران پایین قوی‌تری منجر می‌شد. ولی این روند برای مسئله درخت تصمیم کار نمی‌کند چون وقتی 
 	مسئله را مربع می‌کنیم میانگین طول مسیرها فقط ۲ برابر می‌شود. درنتیجه حل کردن مسئله مربع‌شده با تقریب
 	\lr{$\alpha$}
 	و بازگرداندن جواب به مسئله اصلی به سادگی فاکتور تقریب را حفظ می‌کند(و متاسفانه آن را بهبود نمی‌دهد).
 	نتایج سختی از مرجع ۱ به یک مسئله‌ی مجموعه‌ی موفقیت تکیه می‌کند که جواب‌های بزرگی دارد. این تکنیک‌ها نیز به نظر برای مسئله درخت تصمیم کارا نیستند. بهبود کران بالا نیز منطقی است. برای مثال ما هنوز خانواده‌ای از نمونه‌های مسئله
 	درخت تصمیم پیدا نکرده‌ایم که آنالیز ما برای الگوریتم حریصانه روی آن تنگاتنگ باشد. 
 	\paragraph{}
 	دومین مسئله باز درگیر مسئله درخت تصمیم با اعضای وزن‌دار می‌شود. در حالی که آنالیز ما به حالتی که آزمون‌ها 
 	وزن‌دار باشند تعمیم می‌یابد، برای زمانی که اعضا وزن داشته باشند کار نمی‌کند.
 	دلیل این اتفاق این است که روش ما به ما اجازه نمی‌دهد که به راحتی، وزن گره‌های درخت تشکیل شده از روش حریصانه
 	را با وزن‌های گره‌های درخت بهینه مقایسه کنیم. چون وزن گره فقط با اعضای موجود در زیردرخت آن مشخص نمی‌شود بلکه
 	با وزن کل اعضای موجود در زیردرخت آن مشخص می‌شود. غلبه کردن به این مانع، یک چالش تحلیلی جذاب را ارائه می‌کند.
\end{document}

