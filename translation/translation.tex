\documentclass[a4paper]{article}

\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[tmargin=1in, rmargin=1.25in, bmargin=1in, lmargin=1.25in]{geometry}
\usepackage{pdfpages}
\usepackage{listings}
\usepackage{float}
\usepackage{color}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.96,0.96,0.94}

\lstdefinestyle{mystyle}{
	backgroundcolor=\color{backcolour},   
	commentstyle=\color{codegreen},
	keywordstyle=\color{magenta},
	numberstyle=\tiny\color{codegray},
	stringstyle=\color{codepurple},
	basicstyle=\footnotesize,
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbers=left,                    
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=4
}

\lstset{style=mystyle}
\usepackage{wrapfig}

\usepackage{ptext}
\usepackage{lipsum}

\usepackage{xepersian}
\settextfont{XB Yas}
\setlatintextfont{Arial}
\setdigitfont{Arial}


\title{ترجمه مقاله درس الگوریتم پیشرفته\\
روش تقریبی برای درخت تصمیم دودویی بهینه
}
\author{محمد مهدی حیدری\\۹۴۲۳۰۴۵}
\begin{document}
	\maketitle
	\section*{چکیده}
	\section{مقدمه}
	\paragraph{}
	در این مقاله مسئله تقریب درخت تصمبم دودویی را بررسی می‌کنیم. گری و جانسون مسئله درخت تصمیم را اینگونه تعریف می‌کنند: اگر مجموعه
	\lr{m}
	آزمون دودویی 
	\lr{$T=(T_1,... , T_m)$}
	و مجموعه 
	\lr{n}
	شی 
	\lr{$X=(X_1,..., X_n)$}
	را به ما داده باشند، خروجی یک درخت دودویی است که در آن هر برگ با یکی از اعضای مجموعه 
	\lr{X}
	و هر گره داخلی درخت با یک آزمون از مجموعه 
	\lr{T}
	علامت گذاری شده است. اگر یک شی به یک آزمون پاسخ مثبت بدهد به شاخه
	راست گره مربوط به آن آزمون حرکت می‌کند و اگر پاسخ منفی باشد به شاخه چپ می‌رود. یک مسیر از ریشه درخت تا یک برگ 
	به صورت یکتا یک شی با برچسب آن برگ را مشخص می‌کند. عمق یک برگ برابر با طول مسیر آن از ریشه درخت است.
	طول مسیر کل برای درخت برابر است با مجموع عمق تمام برگ‌های یک درخت. هدف مسئله درخت تصمیم این است که طول مسیر کل
	برای یک درخت را کمینه کند. یک شیوه معادل برای بیان مسئله این است که هر شی را یک رشته 
	\lr{m}
	ببینیم که بیت 
	\lr{i}
	ام آن نشان دهنده نتیجه‌ی آزمون 
	\lr{i}
	ام روی آن شی است که اگر جواب مثبت باشد بیت ۱ و در غیر این صورت ۰ است. در این مقاله از این شیوه از توصیف درخت
	تصمیم مثال‌هایی زده شده است که با اعضایی از مجموعه
	\lr{X}
	آنها را نشان می‌دهیم.
	اگر هیچ دو رشته‌ای در مجموعه
	\lr{X}
	یکسان نباشد، هر راه‌حل ممکن برای مسئله درخت تصمیم
	\lr{n}
	برگ خواهد داشت. در این مقاله فرض می‌کنیم همیشه ورودی یک مجموعه از رشته‌های یکتاست چون پیدا کردن رشته‌های تکراری
	به راحتی در زمان چند جمله‌ای قابل انجام است. درخت‌های تصمیم کاربردهای طبیعی بسیاری دارند از جمله: تشخیص پزشکی
	(مجموعه آزمون، علائم بیماری است.)، طراحی آزمایش (آزمون‌ها، همان آزمایش‌هایی هستند که یک ویژگی را تعیین می‌کند.)
	در واقع هیاویل و رایوست اثبات کردند که مسئله درخت تصمیم 
	\lr{NP-Complete}
	است. چون تلاش بسیاری برای ارائه الگوریتمی که درخت تصمیم بهینه را تولید می‌کند انجام شده بود.
	\paragraph{}
	در این مقاله یک الگوریتم تقریبی 
	\lr{$\ln n + 1$}
	برای مسئله درخت تصمیم ارائه می‌دهیم.
	همچنین نشان می‌دهیم که برای مسئله درخت تصمبم الگوریتم تقریبی زمان چند جمله‌ای وجود ندارد مگر اینکه 
	\lr{P=NP}
	باشد.
	با دانش فعلی ما بهترین حد بالا و پایین غیر بدیهی برای تقریب مسئله درخت تصمبم همین دو هستند.
	با توجه به قدمت زیاد و پرکاربرد بودن این مسئله، اینکه تلاش کمی برای ارائه روش تقریبی برای آن انجام شده به نظر
	اعجاب آور است.
	با این حال بررسی دقیق صورت مسئله مقداری توضیحات را ایجاب می‌کند:
	نام درخت تصمیم به یک مسئله مشابه با اندکی تفاوت نیز اشاره می‌کند که نام آنرا درخت تصمبم سازگار می‌گذاریم.
	مسئله اخیر برای تقریب بسیار سخت است. ورودی این مسئله 
	\lr{n}
	رشته دودویی است که با علامت مثبت و منفی برچسب گذاری شده است، طول هر کدام 
	\lr{m}
	است و نمونه‌های مسئله را تشکیل می‌دهد. خروجی یک درخت دودویی است که هر گره داخلی آن بیت 
	\lr{i}
	ام از نمونه‌‌ها را تست می‌کند و نمونه‌هایی که پاسخ ۱ دادند به شاخه راست و نمونه‌های با پاسخ ۰ را به شاخه چپ نگاشت
	می‌کند. هر برگ یکی از حالت‌های صحیح یا غلط را دارد. یک درخت تصمیم سازگار هر نمونه‌ی با برچسب مثبت را به یک برگ
	با برچسب صحیح و هر نمونه با برچسب منفی را به یک برگ با برچسب غلط نگاشت می‌کند. اندازه درخت در این حالت تعداد
	برگ‌ها است و مسئله درخت تصمیم سازگار به دنبال درخت تصمیمی می‌گردد که با کمترین اندازه با نمونه‌ها سازگاری داشته باشد.
	\paragraph{}
	آلکنویچ و همکارانش نشان دادند که برای هر ثابت نامنفی
	\lr{k}
	نمی‌توان از طریق درخت تصمیم با اندازه
	\lr{$s^k$}
	درخت تصمیم با اندازه
	\lr{s}
	را تخمین زد مگر اینکه
	\lr{$\epsilon < 1$}
	وجود داشته باشد که کلاس
	\lr{NP}
	زیرمجموعه 
	\lr{DTIME[$2^{m^{\epsilon}}$]}
	باشد. این موضوع نتیجه کار هانوک و همکارانش را بهبود می‌دهد که نشان می‌داد هیچ تقریب 
	\lr{$2^{\log^{\delta}s}$}
	یرای درخت تصمیم با اندازه 
	\lr{s}
	وجود ندارد که 
	\lr{$\delta < 1$}
	مگر اینکه کلاس 
	\lr{NP}
	شبه چند جمله‌ای باشد. این نتیجه برای وقتی که اندازه‌ی درخت
	\lr{$\Omega(n)$}
	باشد صادق است.
	\paragraph{}
	نتایج ما نشان می‌دهد که علیرغم ارتباط نزدیک مسئله درخت تصمیم و درخت تصمیم سازگار، این دو مسئله از نظر تقریب پذیری بسیار متفاوت هستند. درخت تصمیم سازگار برای هر ثابت
	\lr{c}
	تقریب 
	\lr{$c\ln n$}
	ندارد مگر اینکه
	\lr{P=NP}
	باشد. این در حالی است که نتایج ما از وجود داشتن چنین تقریبی با ثابت
	\lr{c > 1}
	برای مسئله درخت تصمبم خبر می‌دهد.
	همچنین ما نشان می‌دهیم که حد پایین یادگیری درخت تصمیم از نوع سازگار برای وقتی که بخواهیم به جای تعداد برگ‌ها
	مجموع طول مسیرها را کمینه کنیم نیز برقرار است. لازم به ذکر است که در مسئله درخت تصمیم، اندازه درخت معیار مفیدی
	نیست چون هر جواب ممکن برای این مسئله 
	\lr{n}
	برگ دارد. بنابراین، تفاوت در ورودی و خروجی است که باعث تفاوت در پیچیدگی تقریب این دو مسئله می‌شود و نه معیار.
	\paragraph{}
	جای تعجب ندارد که تفاوت در پیچیدگی تقریب بین مسئله درخت تصمیم و درخت تصمیم سازگار به علاوه‌ی ابهام موجود در اسم
	درخت تصمیم باعث سردرگمی در ادبیات مسئله شده است. برای مثال در ارجاع دوم مسئله درخت تصمیم با توجه به ورودی و
	خروجی همان مسئله تعریف شده ولی از نتایج منفی پژوهش هانوک و همکارانش استفاده شده است. بنابر ایم ما یکی از فعالیت‌های خود را جداسازی مسئله درخت تصمیم و درخت تصمیم سازگار از نظر پیچیدگی تقریب می‌دانیم.
	\paragraph{}
	مورت هر یک از مسائل درخت تصمیم و درخت تصمیم سازگار را نمونه‌های یکتایی از مسئله عمومی درخت تصمیم می‌داند که در آن هر یک از اعضا با یکی از 
	\lr{k}
	برچسب ممکن علامت گذاری شده است. با این فرض در مسئله درخت تصمیم این پارامتر 
	\lr{k}
	برابر با 
	\lr{n}
	است و هر عضو دقیقا یک برچسب دارد و در مسئله درخت تصمیم سازگار ۲ نوع برچسب داریم که برای هر برچسب می‌تواند چند عضو وجود داشته باشد. پس به نظر می‌آید محدودیت روی تنوع برچسب‌ها نقش اساسی در پیچیدگی تقریب در مسائل درخت تصمیم را دارد. 
	\paragraph{}
	مسئله درخت تصمیم مشترکاتی با مسئله پوشش مجموعه‌ای
	\lr{(set cover)}
	دارد. چون هر جفت از اعضا در یک درخت تصمیم معتبر دقیقا یک بار از هم جدا می‌شوند، می‌توانیم مسیر از ریشه تا یک برگ را به نوعی پوشش اعضا فرض کنیم. در این حالت هر برگ یک مسئله پوشش مجموعه‌ای را مشخص می‌کند که در آن باید 
	\lr{n-1}
	عضو باقی مانده را با استفاده از مجموعه مناسبی از بیت‌ها یا به عبارتی آزمون‌ها پوشش دهیم. در واقع آنالیز ما
	از این مشاهده الهام گرفته است. با این حال در مسئله درخت تصمیم،
	\lr{n}
	مجموعه‌ای که توسط برگ‌ها برای پوشش مجموعه‌ای معرفی می‌شوند مستقل نیستند. برای مثال بیتی که در ریشه یک درخت تصمیم
	دودویی بهینه وجود دارد، در همه‌ی
	\lr{n}
	جواب مسئله پوشش مجموعه‌ای تکرار شده است. ولی به راحتی می‌توان نمونه‌هایی از درخت تصمیم ساخت که برای آن 
	\lr{n}
	مجموعه متناظر عضو مشترکی نداشته باشند. به طور دقیق‌تر اگر پاسخ 
	\lr{n}
	مسئله پوشش مجموعه‌ای با اندازه ۱ را که از هم مستقل هستند داشته باشیم، در زمان 
	\lr{$\Theta(n^2)$}
	جواب متناظر آن در مسئله درخت تصمیم را پیدا می‌کنیم در حالی که ساخت درخت تصمیم بهینه هزینه‌ی
	\lr{$O(n\log n)$}
	دارد. در نتیجه فعل و انفعال بین مسائل پوشش مجموعه‌ای منحصر بفرد و مسئله درخت تصمیم، ظاهرا باعث تفاوت بنیادین بین این دو می‌شود.
	\paragraph{}
	مسئله پوشش مجموعه‌ای با کمترین مجموع نیز مشابه مسئله درخت تصمیم است. ورودی این مسئله مانند پوشش مجموعه‌ای است
	(مجموعه جهانی از اعضا 
	\lr{X}
	و مجموعه
	\lr{C}
	که هر عضو آن یک زسر مجموعه از 
	\lr{X}
	باشد.
	)
	، ولی خروجی یک ترتیب خطی از مجموعه‌های ۱ تا
	\lr{|C|}
	است. اگر 
	\lr{f(x)}
	اندیس اولین مجموعه از ترتیب که 
	\lr{x}
	را پوشش می‌دهد به ما بدهد، هزینه این ترتیب
	\lr{$\sum_{x\in X} f(x)$}
	خواهد بود. این هزینه با هزینه‌ی درخت تصمیم متناظر مشابه است ولی یکسان نیست چون اعضای پوشش داده شده باید همچنان
	از هم جدا شوند و در نتیجه به هزینه افزوده می‌شود. اگر به طور حریصانه مجموعه‌ای را انتخاب کنیم که بیشترین اعضای
	پوشش داده نشده را پوشش بدهد، به پاسخی تقریبی با فاکتور ۴ از مسئله پوشش مجموعه‌ای با کمترین جمع می‌رسیم. این فاکتور تقریب تنگاتنگ است مگر اینکه
	\lr{P=NP}
	برقرار باشد. مشابه مسئله پوشش مجموعه‌ای، می‌توانیم به درخت تصمیم مانند 
	\lr{n}
	نمونه از پوشش مجموعه‌ای با کمترین جمع نگاه کنیم، ولی مجددا این نمونه‌ها مستقل نیستند. پس مشکل ذاتی که برای
	مسئله پوشش مجموعه‌ای وجود داشت، در مسئله پوشش مجموعه‌ای با کمترین جمع نیز باقی می‌ماند. 
	\paragraph{}
	در قسمت بعدی الگوریتم تقریبی خود برای درخت تصمیم را توصیف و آنالیز می‌کنیم. همچنین حالتی را که به هر آزمون
	\lr{t}
	وزن داده‌شود نیز ملاحظه و می‌کنیم و نشان می‌دهیم که به فاکتور تقریب 
	\lr{$\ln n + 1$}
	نقصی وارد نمی‌شود. در قسمت سوم نشان می‌دهیم که 
	\lr{$\delta > 0$}
	پیدا می‌شود به طوری که مسئله درخت تصمیم تقریبی با فاکتور 
	\lr{$1+\delta$}
	نداشته باشد مگر اینکه
	\lr{P=NP} 
	باشد. علاوه بر این نشان می‌دهیم که کران پایین برای یادگیری درخت تصمیم سازگار برای مجموع طول مسیرهای خارجی نیز
	برقرار است. در آخر با بحث روی بعضی مسائل باز که فاصله‌ی بین کران کران بالا و پایین را شامل می‌شوند نتیجه گیری
	را انجام می‌دهیم. 
	\section{تقریب مسئله درخت تصمیم}
	\paragraph{}
	با داشتن مجموعه‌ای از رشته‌های 
	\lr{m}
	بیتی به نام
	\lr{S}
	، انتخاب یک بیت
	\lr{i}
	همواره اعضا را به دو مجموعه 
	\lr{$S^0$}
	و 
	\lr{$S^1$}
	تقسیم می‌کند که به ترتیب شامل رشته‌های با بیت
	\lr{i=0}
	و
	\lr{i=1}
	هستند. یک روش حریصانه این است که بیت
	\lr{i}
	را طوری انتخاب کنیم که اندازه این دو مجموعه کمترین اختلاف را با هم داشته باشند یا به عبارتی مجموعه
	\lr{S}
	را به متوارن‌ترین حالت ممکن بخش بندی کنند. الگوریتم حریصانه مقابل برای ساخت درخت تصمیم با مجموعه اعضای 
	\lr{n}
	عضوی به نام
	\lr{X}
	را ملاحظه کنید:
	\newpage
	\begin{figure}[h!]
		\centering
		\includegraphics[width=0.7\linewidth]{Pics/Greedy.png}
		\caption{الگوریتم حریصانه برای ساختن درخت تصمیم}
	\end{figure}
	\paragraph{}
	یک پیاده‌سازی سرراست این الگوریتم در زمان 
	\lr{$O(mn^2$}.
	در حالی که این الگوریتم همیشه جواب بهینه را نمی‌دهد، آنرا با فاکتور 
	\lr{$\ln n + 1$}
	تقریب می‌زند.
	\paragraph{قضیه ۱}
	اگر
	\lr{X}
	یک نمونه از درخت تصمیم با
	\lr{n}
	عضو باشد و هزینه بهینه
	\lr{$C^*$}
	باشد، آنگاه الگوریتم حریصانه درختی با هزینه‌ی حداکثر 
	\lr{$(\ln n + 1)C^*$}
	تولید می‌کند.
	\paragraph{اثبات}
	با یک نمادگذاری آغاز می‌کنیم. فرض کنید 
	\lr{T}
	درخت تصمیمی با هزینه‌ی
	\lr{C}
	باشد که الگوریتم حریصانه روی مجموعه
	\lr{X}
	ساخته است. یک جفت عضو یدون ترتیب
	\lr{\{x, y\}}
	(از این به بعد فقط یک جفت عضو) توسط گره داخلی 
	\lr{S}
	از هم جدا می‌شوند اگر 
	\lr{x}
	در یک شاخه و
	\lr{y}
	در شاخه‌ی دیگر قرار بگیرد. به خاطر داشته باشید که در یک درخت تصمیم معتبر هر جفت عضو دقیقا یک بار از هم جدا می‌شوند. بالعکس هر گره داخلی 
	\lr{S}
	مجموعه‌ای به نام 
	\lr{$\rho (S)$}
	تشکیل تعریف می‌کند که اعضای آن جفت‌هایی از اعضا هستند که توسط 
	\lr{S}
	از هم جدا شده‌اند. به این صورت:
	\[\rho(S) = \{\{x,y\}| \{x,y\} \; is \; separated \; at \; S\}\]
	برای راحتی از 
	\lr{S}
	برای نشان دادن زیردرخت‌هایی که از 
	\lr{S}
	منشعب شده‌اند نیز استفاده می‌کنیم.
	فرض کنید
	\lr{$S^+$}
	و
	\lr{$S^-$}
	دو فرزند
	\lr{S}
	باشند به طوری که 
	\lr{$|S^+| \ge |S^-|$}.
	به یاد داشته باشید که
	\lr{$|S| = |S^+| + |S^-|$}.
	تعداد مجموعه‌هایی که یک عضو به آن تعلق دارد، با طول مسیر آن از ریشه برابر است، پس هزینه
	\lr{T}
	را می‌توان با جمع اندازه‌‌های هر مجموعه
	\lr{S}
	نشان داد:
	\[C=\sum_{S\in T} |S|\]
	ما در آنالیز خود از روش بانکداری استفاده می‌کنیم تا هزینه‌ی کل درخت تصمیم حریصانه را بین تمام جفت‌های بدون ترتیبی که معرفی کردیم، پخش کنیم. چون هر مجموعه
	\lr{S}
	به اندازه اندازه خود در هزینه‌ی کل سهیم است، ما سایز آنرا به طور یکنواخت بین 
	\lr{$|S^+||S^-|$}
	جفت‌هایی از اعضا که در 
	\lr{S}
	از هم جدا شده‌اند تقسیم می‌کنیم. فرض کنید
	\lr{$c_{xy}$}
	هزینه‌ای باشد که به هر جفت عضو
	\lr{\{x, y\}}
	نسبت می‌دهیم که:
	\[c_{xy} = \frac{1}{S^{+}_{xy}}+\frac{1}{S^{-}_{xy}}\]
	در جمع سهیم هستند و هر گره
	\lr{y}
	در 
	\lr{$Z^-$}
	به اندازه:
	\[\sum_{x\in Z^+} \frac{1}{|S_{xy} \cap Z^+|}\]
	در جمع سهم دارد. برای روشن شدن موضوع، می‌توانیم 
	\lr{Z}
	را به عنوان یک گراف دو بخشی کامل ببینیم که 
	\lr{$Z^+$}
	یک بخش گره‌های آن و 
	\lr{$Z^-$}
	بخش دیگر است.
	فرض کنید 
	$b_{xy} = \frac{1}{(|S_{xy} \cap Z^-|)}$
	و
	$b_{yx} = \frac{1}{(|S_{xy} \cap Z^+|)}$
	باشد. می‌توانیم فرض کنیم که هر یال
	\newline
	\lr{(x, y)}
	که در آن
	\lr{$x \in Z^+$}
	و 
	\lr{$y \in Z^-$}
	دو هزینه دارد: یکی مربوط به 
	\lr{$x(b_{yx})$}
	و دیگری 
	\lr{$y(b_{yx})$}.
	بنابراین، هزینه‌ی کل هزینه‌ی 
	\lr{Z}
	حداکثر برابر با جمع تمام هزینه‌های
	\lr{$b_{xy}$}
	و 
	\lr{$b_{yx}$}
	است. ما می‌توانیم هزینه‌ی کل را در ابتدا با محدود کردن تمام هزینه‌های مربوط به یک گره را محدود کنیم.
	به طور خاص ما ادعا میکنیم:
	\paragraph{ادعا}
	برای هر 
	\lr{$x \in Z^+$}
	داریم:
	\[\sum_{y\in Z^-}b_{xy} = \sum_{y\in Z^-} \frac{1}{|S_{xy} \cap Z^-|} \le H(|Z^-|) \]
	\paragraph{اثبات}
	اگر 
	\lr{$Z^-$}
	\lr{m}
	عضو داشته باشد، آنگاه فرض کنید
	\lr{$(y_1,...,y_m)$}
	ترتیبی از 
	\lr{$Z^-$}
	باشد به طوری که هر چه یک عضو در درخت تصمیم حریصانه زودتر از 
	\lr{x}
	جدا شده باشد، در این ترتیب دیرتر ظاهر شده باشد (ترتیب معکوس و حالات تساوی به نحو دلخواهی شکسته شده باشد). 
	این بدین معناست که 
	\lr{$y_1$}
	آخرین و 
	\lr{$y_m$}
	اولین عضوی باشد که از 
	\lr{x}
	جدا شده است و به طور کلی
	\lr{$y_{m-t+1}$}
	\lr{t}
	امین عضوی است که از 
	\lr{x}
	جدا شده است. هنگامی که 
	\lr{$y_m$}
	از 
	\lr{x}
	جدا می‌شود، باید حداقل
	\lr{$|Z^-|$}
	عضو در 
	\lr{$S_{xym}$}
	وجود داشته باشد. با ترتیبی که ما در نظر گرفتیم اعضای باقی مانده در 
	\lr{$Z^-$}
	باید همچنان حضور داشته باشند پس:
	\lr{$Z^- \subseteq S_{xym}$}
	. بنایراین هزینه‌ای که به گره
	\lr{x}
	بخاطر یال 
	\lr{$(x, y_m)$}
	منسوب می‌شود، حداکثر
	\lr{$\frac{1}{|Z^-|}$}
	است و در حالت کلی وقتی 
	\lr{$y_t$}
	از 
	\lr{x}
	جدا می‌شود، حداقل 
	\lr{t}
	عضو از 
	\lr{$Z^-$}
	باقی می‌ماند پس هزینه
	\lr{$b_{xyt}$}
	که به یال
	\lr{$(x, y_t)$}
	نسبت داده شده حداکثر
	\lr{$\frac{1}{t}$}
	می‌شود. این بدین معناست که برای هر
	\lr{$x \in Z_+$}:
	\[\sum_{y\in Z^-} b_{xy} \le H(|Z^-|) \]
	که ادعا را ثابت می‌کند. 
	\paragraph{}
	می‌توانیم همین استدلال را برای ادعایی مشابه برای همه‌ی اعضای موجود در 
	\lr{$Z^-$}
	استفاده کنیم. با داشتن این نامساوی‌ها خواهیم داشت:
	\[\sum_{\{x,y\}\in \rho(Z)} \frac{1}{|S_{xy} \cap Z^+|} + \frac{1}{|S_{xy} \cap Z^-|} 
	\le |Z^+|H(|Z^-|) + |Z^-|H(|Z^+|)\]
	\[< |Z^+|H(|Z|) + |Z^-|H(|Z|)\]
	\[< |Z|H(|Z|)\; (since \; |Z^+|+|Z^-|=|Z|)\]
	با تعویض این نتیجه با نامساوی ابتدایی، اثبات قضیه کامل می‌شود.
	\[\sum_{Z \in T^*} \sum_{\{x,y\}\in \rho(Z)} c_{xy} \le \sum_{Z \in T^*} |Z|H(|Z|) \le \sum_{Z \in T^*} 
	|Z|H(n) = H(n)C^* \le (\ln n + 1)C^*\]
	\subsection{حالت آزمون‌های وزن دار}
	\paragraph{}
	در بسیاری از کاربردها ممکن است آزمون‌های مختلف هزینه‌های اجرای مختلفی داشته باشند. برای مثال در طراحی آزمایش
	یک آزمون تکی ممکن است تمییز دهنده‌ی خوبی برای اعضا باشد، ولی در عین حال پرهزینه باشد. اجرای چند آزمون کم‌هزینه
	می‌تواند هدف کلی را برآورده کند ولی هزینه‌ی کمتری به همراه داشته باشد. برای مدل کردن چنین سناریوهایی، ما به هر 
	بیت
	\lr{k}
	وزن
	\lr{w(k)}
	را نسبت می‌دهیم و بدون سردرگمی می‌توانیم 
	\lr{w(S)}
	را برای بیتی که در گره
	\lr{S}
	استفاده شده به کار ببریم.
	ما این مسئله را درخت تصمیم با آزمون‌های وزندار می‌نامیم. در بیان ریاضی مسئله اصلی، می‌توانیم فرض کنیم که هر آزمون وزن ۱ دارد پس هزینه معین کردن هر عضو همان طول مسیر از ریشه تا آن عضو می‌باشد. وقتی که آزمون‌ها وزن‌های غیر یکنواخت دارند، هزینه‌ی تعیین یک عضو برابر با جمع وزن‌های آزمون‌ها از ریشه تا آن عضو است که نام آن را هزینه مسیر می‌گذاریم. در نتیجه هزینه‌ی یک درخت تصمیم برابر با جمع هزینه‌ی مسیر هر عضو است. وقتی همه‌ی آزمون‌ها هزینه‌ي یکسانی دارند ما بیتی را انتخاب می‌کنیم که به مساوی‌ترین شکل ممکن اعضا را به دو گروه تفسیم می‌کند. به زبانی دیگر ما هزینه جفتی 
	\lr{$c_{xy}$}
	را کمینه می‌کنیم. با وزن‌های مساوی، هزینه‌ی یک گره داخلی همان اندازه
	\lr{S}
	است در حالی که وقتی وزن‌ها نامساوی باشند، این هزینه
	\lr{w(S) |S|}
	خواهد بود. بنابراین با فرض اینکه 
	\lr{S}
	،
	\lr{x}
	و
	\lr{y}
	را از هم جدا می‌کند، هزینه‌ي جفتی می‌شود:
	\[c_{xy} = \frac{w(S)}{|S^+|} + \frac{w(S)}{|S^-|}\]
	و الگوریتم حریصانه‌ی ما به طور بازگشتی آن بیتی را انتخاب می‌کند که این مقدار را کمینه کند. این روند منجر به
	نتیجه‌ای معادل با قضیه ۱ برای درخت تصمیم با آزمون‌های وزندار می‌شود. یک پیاده‌سازی سرراست از این الگوریتم همچنان
	در زمان
	\lr{$O(mn^2)$}
	اجرا می‌شود.  
	\paragraph{قضیه ۲}
	الگوریتم حریصانه‌ای که به طور بازگشتی بیتی را انتخاب می‌کند که معادله قبل را کمینه کند، به تقریب 
	\lr{$\ln n + 1$}
	مسئله درخت تصمیم با آزمون‌های وزن‌دار منجر می‌شود.
	\paragraph{اثبات}
	با پیروی از قواعد اثباتی که برای قضیه ۱ ارائه شد، به نتیجه‌ی مطلوب می‌رسیم. مشاهده اساسی این است که انتخاب
	بیتی که معادله را کمینه کند به این نامساوی می‌انجامد:
	\[c_{xy} \le w(Z) (\frac{1}{|S_{xy} \cap Z^+|} + \frac{1}{|S_{xy} \cap Z^-|})\]
	جون عبارت
	\lr{w(Z)}
	از جمع به بیرون فاکتور گرفته می‌شود،
	\[w(Z) \sum_{\{x,y\}\in \rho(Z)} c_{xy} \le \sum_{Z \in T^*} w(Z)|Z| H(n) \le (\ln n + 1)C^* \]
	می‌توانیم ادعای قبلی را اعمال کنیم و قضیه بدین صورت ادامه می‌یابد:
	\[\sum_{Z \in T^*} \sum_{\{x,y\}\in \rho(Z)} c_{xy} \le \sum_{Z \in T^*} w(Z)|Z|H(n) \le (\ln n + 1)C^*\]
	در اینجا 
	$C^* = \sum_{Z \in T^*} w(Z)|Z|$
	هزینه درخت بهینه است.
	\paragraph{}
	یکی دیگر از افزونه‌های طبیعی مسئله درخت تصمیم به حساب آوردن وزن برای اعضا است. در اینجا هر مسیر با عضوی که
	مسیر به آن تعلق دارد وزندهی می‌شود. متاسفانه آنالیز ما برای این حالت برقرار نیست و در بخش ۵ بیشتر درباره آن
	بحث می‌کنیم. 
	\begin{figure}[h!]
		\includegraphics[width=\linewidth]{Pics/tree.png}
		\caption{توپولوژی یک درخت بهینه}
	\end{figure}
	\section{تقریب درخت تصمیم مسئله‌ای سخت است.}
\end{document}

